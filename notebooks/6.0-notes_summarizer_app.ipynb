{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install langchain_openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# loading from a .env file\n",
    "# load_dotenv(dotenv_path=\"/full/path/to/your/.env\")\n",
    "\n",
    "# or \n",
    "# if you're on google colab just uncomment below and replace with your openai api key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your-openai-api-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes Summarizer App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Nielsen\\'s essay \"Reinventing Explanation\" explores the potential of non-traditional media as powerful tools for deeper explanations, particularly in scientific and mathematical contexts. Nielsen argues that such media should not be seen merely as vehicles for popularization or education but as opportunities to create more profound and nuanced understandings.\\n\\nHe uses the example of the London Underground map to illustrate how certain representations can become internalized, transforming the way we think about complex systems. Similarly, he discusses how a new vocabulary of operations for difference equations can change our approach to mathematical thinking.\\n\\nNielsen envisions a future where these dynamic problem-solving mediums expand our cognitive capabilities, especially in mathematics. He focuses on designing media that explain scientific ideas more effectively, suggesting that we currently lack a basic vocabulary for digital explanations. He believes that developing prototypes and learning from them is the way forward.\\n\\nThe essay emphasizes that the goal is not to make concepts popular for the masses but to explore the potential of non-traditional media for serious, in-depth explanations used by scientists. Nielsen concludes by discussing optimization, specifically the process of minimizing a loss function to improve the quality of a set of weights, as an example of how these new media can enhance our understanding of complex problems.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_response(prompt):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(model=\"gpt-4o\", \n",
    "                             messages=\n",
    "                             [\n",
    "                                 {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                                 {\"role\": \"user\", \"content\": prompt}   \n",
    "                             ],\n",
    "                             temperature=0.0,\n",
    "                             )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "notes_path = \"./Reinventing-explanation.txt\"\n",
    "with open(notes_path, \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "get_response(f\"Summarize this text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok , great we can get a basic summary easy using just ChatGPT, but how about if we want to be able to specify different types of summaries? \n",
    "What if the contents we want to summarize are bigger than the context length of our model?\n",
    "\n",
    "Let's address these issues by using langchain for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With langchain, summarization is as simple as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(metadata={'source': './Reinventing-explanation.txt'}, page_content='[source](https://michaelnielsen.org/reinventing_explanation/index.html)\\nMedia for thought. #intelligence #learning #problemsolving \\n[[A dynamic problem solving medium]]\\n\\nMiachel Nielsen in his [[Reinventing-explanation]], says:\\n\\n> I believe it\\'s worth taking non-traditional media seriously not just as a vehicle for popularization or education, which is how they are often viewed, but as an opportunity for explanations which can be, in important ways, deeper. Nielsen, [[Reinventing-explanation]], conclusion\\n\\n> This agglomeration of ideas has turned maps into a powerful _medium for thought_. Consider the famous map of the London Underground, excerpted here: \\n\\n> we internalize the map: the representations used in the map become the representations we use to think about the Underground. This is the sense in which this map is a medium for thought.\\n\\n> He\\'s created a vocabulary of operations which can be used to understand and manipulate and, most crucially of all, _play_ with difference equations. And with enough exposure to this medium, we\\'d begin internalizing these operations: we\\'d begin to think about difference equations in this way.\\n\\nNielsen\\'s see this approach as the future of thinking about mathematics for example where mediums like these could expand how we think about mathematical objects.\\n\\nHe now turns his attention to the design of a tool like this.\\n> In the remainder of this essay I will focus on the design of a particular type of media for thought, namely, ***the design of media to _explain_ scientific ideas.***\\n\\nUsing non-traditional media to create deeper explanations of scientific ideas.\\n\\n> In fact, we don\\'t yet have even the basic vocabulary of digital explanation. My instinct is that such a vocabulary will be developed in the decades to come. But that is far too big a goal to attack directly. Instead, we can make progress by constructing prototypes, and learning from what they have to tell us. That\\'s what we\\'ll do in this essay. Nielsen *\"Reinventing Explanation\"*\\n\\nIt\\'s not about making a concept popular for the \"masses\"...\\n> (...)it\\'s about understanding **the potential of non-traditional media for serious explanations**, the sort of explanations scientists use amongst themselves. So while it happens to be true that the explanations we\\'ll discuss are accessible to a broad audience, what matters is that those explanations are, in some important ways, deeper than conventional verbal and symbolic explanations.\\n\\nSimpson\\'s paradox:\\n\\nSome paradox where the overall probability favors one event as the local probabilities all individually favor the other event in a universe of just these two events.\\n\\n<span style=\"color: gray\">I could write about what it means to understand something from the perspective of these medium for thought tools. </span> \\n\\n\\n\\n\\n\\n\\n\\n\\nHere we are talking about optimization. \\n\\n> To reiterate, the loss function lets us quantify the quality of any particular set of weights W. The goal of optimization is to find W that minimizes the loss function. We will now motivate and slowly develop an approach to optimizing the loss function. \\n')],\n",
       " 'output_text': 'Michael Nielsen explores the potential of non-traditional media for creating deeper explanations of scientific ideas. He emphasizes the importance of developing a vocabulary for digital explanation and focuses on designing media to explain scientific concepts. Nielsen believes that using dynamic problem-solving mediums can enhance our understanding of complex mathematical and scientific concepts, ultimately leading to deeper insights. He also discusses the concept of optimization and the importance of minimizing loss functions in problem-solving.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = TextLoader(notes_path).load()\n",
    "llm = ChatOpenAI()\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\") #stuff means everything goes inside the model's prompt\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as always, we would like to go beyond, why not set up a prompt template to allow for some customization of the summaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m prompt_summarization \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(prompt_template)\n\u001b[1;32m     12\u001b[0m chain \u001b[38;5;241m=\u001b[39m load_summarize_chain(llm, chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompt\u001b[38;5;241m=\u001b[39mprompt_summarization)\n\u001b[0;32m---> 13\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43m[source](https://michaelnielsen.org/reinventing_explanation/index.html)\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43mMedia for thought. #intelligence #learning #problemsolving \u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m[[A dynamic problem solving medium]]\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43mMiachel Nielsen in his [[Reinventing-explanation]], says:\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m> I believe it\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms worth taking non-traditional media seriously not just as a vehicle for popularization or education, which is how they are often viewed, but as an opportunity for explanations which can be, in important ways, deeper. Nielsen, [[Reinventing-explanation]], conclusion\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43m> This agglomeration of ideas has turned maps into a powerful _medium for thought_. Consider the famous map of the London Underground, excerpted here: \u001b[39;49m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m> we internalize the map: the representations used in the map become the representations we use to think about the Underground. This is the sense in which this map is a medium for thought.\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43m> He\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms created a vocabulary of operations which can be used to understand and manipulate and, most crucially of all, _play_ with difference equations. And with enough exposure to this medium, we\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md begin internalizing these operations: we\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md begin to think about difference equations in this way.\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;43mNielsen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms see this approach as the future of thinking about mathematics for example where mediums like these could expand how we think about mathematical objects.\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43mHe now turns his attention to the design of a tool like this.\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43m> In the remainder of this essay I will focus on the design of a particular type of media for thought, namely, ***the design of media to _explain_ scientific ideas.***\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43mUsing non-traditional media to create deeper explanations of scientific ideas.\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;43m> In fact, we don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt yet have even the basic vocabulary of digital explanation. My instinct is that such a vocabulary will be developed in the decades to come. But that is far too big a goal to attack directly. Instead, we can make progress by constructing prototypes, and learning from what they have to tell us. That\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms what we\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mll do in this essay. Nielsen *\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReinventing Explanation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43mIt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms not about making a concept popular for the \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmasses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m...\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43m> (...)it\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms about understanding **the potential of non-traditional media for serious explanations**, the sort of explanations scientists use amongst themselves. So while it happens to be true that the explanations we\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mll discuss are accessible to a broad audience, what matters is that those explanations are, in some important ways, deeper than conventional verbal and symbolic explanations.\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;43mSimpson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms paradox:\u001b[39;49m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;43mSome paradox where the overall probability favors one event as the local probabilities all individually favor the other event in a universe of just these two events.\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;43m<span style=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolor: gray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>I could write about what it means to understand something from the perspective of these medium for thought tools. </span> \u001b[39;49m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;43mHere we are talking about optimization. \u001b[39;49m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;43m> To reiterate, the loss function lets us quantify the quality of any particular set of weights W. The goal of optimization is to find W that minimizes the loss function. We will now motivate and slowly develop an approach to optimizing the loss function. \u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m Markdown(summary)\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:138\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    137\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 138\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:243\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m, docs: List[Document], callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    231\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stuff all documents into one prompt and pass to LLM.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m        element returned is a dictionary of other keys to return.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs), {}\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:199\u001b[0m, in \u001b[0;36mStuffDocumentsChain._get_inputs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03mFormat and then join all the documents together into one input with name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Format each document according to the prompt\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m doc_strings \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mformat_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    202\u001b[0m     k: v\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[1;32m    205\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:199\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03mFormat and then join all the documents together into one input with name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Format each document according to the prompt\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m doc_strings \u001b[38;5;241m=\u001b[39m [\u001b[43mformat_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_prompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    202\u001b[0m     k: v\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[1;32m    205\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain_core/prompts/base.py:405\u001b[0m, in \u001b[0;36mformat_document\u001b[0;34m(doc, prompt)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_document\u001b[39m(doc: Document, prompt: BasePromptTemplate[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format a document into a string based on a prompt template.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    First, this pulls information from the document from two sources:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m            >>> \"Page 1: This is a joke\"\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43m_get_document_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-chatgpt-apps/lib/python3.11/site-packages/langchain_core/prompts/base.py:357\u001b[0m, in \u001b[0;36m_get_document_info\u001b[0;34m(doc, prompt)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_document_info\u001b[39m(doc: Document, prompt: BasePromptTemplate[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m--> 357\u001b[0m     base_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_content\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdoc\u001b[38;5;241m.\u001b[39mmetadata}\n\u001b[1;32m    358\u001b[0m     missing_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(prompt\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(base_info)\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_metadata) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following text:\n",
    "\n",
    "{text}\n",
    "\n",
    "The summary should be in this style: {style}.\n",
    "Let's think step by step.\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "prompt_summarization = ChatPromptTemplate.from_template(prompt_template)\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt_summarization)\n",
    "summary = chain.invoke({\"input_documents\": docs, \"style\": \"concise\"})\n",
    "Markdown(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's wrap this into a streamlit app to allow for a nice looking user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notes summarize example](https://platform.openai.com/examples/default-meeting-notes-summarizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-chatgpt-apps",
   "language": "python",
   "name": "oreilly-chatgpt-apps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
