{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz App\n",
    "\n",
    "- Given a page of a pdf\n",
    "- Given a concept\n",
    "- Simple interface\n",
    "- Quickly generate flexible quizzes\n",
    "  - Generate any type of questions (True or False, text based questions, multiple choice)\n",
    "- Feedback on the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and\\\n",
    "            programming assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "prompt = \"Create a quiz about the basics of Python programming.\"\n",
    "quiz_python = get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Here's a quiz about the basics of Python programming:\n",
       "\n",
       "1. What is Python?\n",
       "a) A snake\n",
       "b) A programming language\n",
       "c) A type of database\n",
       "\n",
       "2. Which of the following is NOT a Python data type?\n",
       "a) Integer\n",
       "b) String\n",
       "c) Boolean\n",
       "d) Character\n",
       "\n",
       "3. What is the correct syntax to output \"Hello, World!\" in Python?\n",
       "a) Console.log(\"Hello, World!\")\n",
       "b) print(\"Hello, World!\")\n",
       "c) System.out.println(\"Hello, World!\")\n",
       "d) printf(\"Hello, World!\")\n",
       "\n",
       "4. How do you create a variable in Python?\n",
       "a) var name = \"John\"\n",
       "b) let name = \"John\"\n",
       "c) name = \"John\"\n",
       "d) $name = \"John\"\n",
       "\n",
       "5. What is the correct way to declare a function in Python?\n",
       "a) def myFunction:\n",
       "b) function myFunction():\n",
       "c) def myFunction():\n",
       "d) function myFunction:\n",
       "\n",
       "6. What is the result of the following code snippet: print(3 + 5 * 2)?\n",
       "a) 11\n",
       "b) 16\n",
       "c) 13\n",
       "d) 13.5\n",
       "\n",
       "7. How do you check if two variables are equal in Python?\n",
       "a) x == y\n",
       "b) x = y\n",
       "c) x.equals(y)\n",
       "d) x === y\n",
       "\n",
       "8. What is the correct syntax to comment a single line in Python?\n",
       "a) // This is a comment\n",
       "b) /* This is a comment */\n",
       "c) # This is a comment\n",
       "d) <!-- This is a comment -->\n",
       "\n",
       "9. How can you convert a string to an integer in Python?\n",
       "a) toInteger()\n",
       "b) int()\n",
       "c) convertToInt()\n",
       "d) toString()\n",
       "\n",
       "10. What is the correct way to write an if statement in Python?\n",
       "a) if x == 5 then:\n",
       "b) if x == 5:\n",
       "c) if(x == 5)\n",
       "d) if x == 5 {\n",
       "\n",
       "Answers:\n",
       "1. b) A programming language\n",
       "2. d) Character\n",
       "3. b) print(\"Hello, World!\")\n",
       "4. c) name = \"John\"\n",
       "5. c) def myFunction():\n",
       "6. a) 11\n",
       "7. a) x == y\n",
       "8. c) # This is a comment\n",
       "9. b) int()\n",
       "10. b) if x == 5:\n",
       "\n",
       "How did you do?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "Markdown(quiz_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements for the app\n",
    "\n",
    "1. We have to be specific\n",
    "   1. We want to specify the number of questions we want\n",
    "2. We have to be able to feed in contextual information\n",
    "3. We want to be able to specify the types of questions we want created (T/F, multiple choice, text...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are an expert quiz maker for technical fields. Let's think step by step and\n",
    "create a quiz with {num_questions} {quiz_type} questions about the following concept/content: {quiz_context}.\n",
    "\n",
    "The format of the quiz could be one of the following:\n",
    "- Multiple-choice: \n",
    "- Questions:\n",
    "    <Question1>: <a. Answer 1>, <b. Answer 2>, <c. Answer 3>, <d. Answer 4>\n",
    "    <Question2>: <a. Answer 1>, <b. Answer 2>, <c. Answer 3>, <d. Answer 4>\n",
    "    ....\n",
    "- Answers:\n",
    "    <Answer1>: <a|b|c|d>\n",
    "    <Answer2>: <a|b|c|d>\n",
    "    ....\n",
    "    Example:\n",
    "    - Questions:\n",
    "    - 1. What is the time complexity of a binary search tree?\n",
    "        a. O(n)\n",
    "        b. O(log n)\n",
    "        c. O(n^2)\n",
    "        d. O(1)\n",
    "    - Answers: \n",
    "        1. b\n",
    "- True-false:\n",
    "    - Questions:\n",
    "        <Question1>: <True|False>\n",
    "        <Question2>: <True|False>\n",
    "        .....\n",
    "    - Answers:\n",
    "        <Answer1>: <True|False>\n",
    "        <Answer2>: <True|False>\n",
    "        .....\n",
    "    Example:\n",
    "    - Questions:\n",
    "        - 1. What is a binary search tree?\n",
    "        - 2. How are binary search trees implemented?\n",
    "    - Answers:\n",
    "        - 1. True\n",
    "        - 2. False\n",
    "- Open-ended:\n",
    "- Questions:\n",
    "    <Question1>: \n",
    "    <Question2>:\n",
    "- Answers:    \n",
    "    <Answer1>:\n",
    "    <Answer2>:\n",
    "Example:\n",
    "    Questions:\n",
    "    - 1. What is a binary search tree?\n",
    "    - 2. How are binary search trees implemented?\n",
    "    \n",
    "    - Answers: \n",
    "        1. A binary search tree is a data structure that is used to store data in a sorted manner.\n",
    "        2. Binary search trees are implemented using linked lists.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are an expert quiz maker for technical fields. Let's think step by step and\\ncreate a quiz with 3 multiple-choice questions about the following concept/content: Data Structures in Python Programming.\\n\\nThe format of the quiz could be one of the following:\\n- Multiple-choice: \\n- Questions:\\n    <Question1>: <a. Answer 1>, <b. Answer 2>, <c. Answer 3>, <d. Answer 4>\\n    <Question2>: <a. Answer 1>, <b. Answer 2>, <c. Answer 3>, <d. Answer 4>\\n    ....\\n- Answers:\\n    <Answer1>: <a|b|c|d>\\n    <Answer2>: <a|b|c|d>\\n    ....\\n    Example:\\n    - Questions:\\n    - 1. What is the time complexity of a binary search tree?\\n        a. O(n)\\n        b. O(log n)\\n        c. O(n^2)\\n        d. O(1)\\n    - Answers: \\n        1. b\\n- True-false:\\n    - Questions:\\n        <Question1>: <True|False>\\n        <Question2>: <True|False>\\n        .....\\n    - Answers:\\n        <Answer1>: <True|False>\\n        <Answer2>: <True|False>\\n        .....\\n    Example:\\n    - Questions:\\n        - 1. What is a binary search tree?\\n        - 2. How are binary search trees implemented?\\n    - Answers:\\n        - 1. True\\n        - 2. False\\n- Open-ended:\\n- Questions:\\n    <Question1>: \\n    <Question2>:\\n- Answers:    \\n    <Answer1>:\\n    <Answer2>:\\nExample:\\n    Questions:\\n    - 1. What is a binary search tree?\\n    - 2. How are binary search trees implemented?\\n    \\n    - Answers: \\n        1. A binary search tree is a data structure that is used to store data in a sorted manner.\\n        2. Binary search trees are implemented using linked lists.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(num_questions=3, quiz_type=\"multiple-choice\", quiz_context=\"Data Structures in Python Programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=ChatOpenAI(temperature=0.0),\n",
    "                 prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_response = chain.run(num_questions=3, quiz_type=\"multiple-choice\", quiz_context=\"Data Structures in Python Programming\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Great! Let's create a multiple-choice quiz about Data Structures in Python Programming. Here's the format:\n",
       "\n",
       "- Questions:\n",
       "    1. What is a data structure?\n",
       "        a. A way to store and organize data\n",
       "        b. A programming language\n",
       "        c. A mathematical equation\n",
       "        d. A sorting algorithm\n",
       "    2. Which data structure is used to store data in a sorted manner?\n",
       "        a. Stack\n",
       "        b. Queue\n",
       "        c. Linked List\n",
       "        d. Binary Search Tree\n",
       "    3. What is the time complexity of searching in a binary search tree?\n",
       "        a. O(n)\n",
       "        b. O(log n)\n",
       "        c. O(n^2)\n",
       "        d. O(1)\n",
       "\n",
       "- Answers:\n",
       "    1. a\n",
       "    2. d\n",
       "    3. b\n",
       "\n",
       "Feel free to modify or add more questions if needed!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(quiz_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_response = chain.run(num_questions=5, quiz_type=\"True-false\", quiz_context=\"3D Printing\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "True-false quiz about 3D Printing:\n",
       "\n",
       "Questions:\n",
       "1. 3D printing is a process of creating a physical object from a digital model. (True|False)\n",
       "2. 3D printers can only create objects using plastic materials. (True|False)\n",
       "3. 3D printing is also known as additive manufacturing. (True|False)\n",
       "4. 3D printers can only create small objects with limited dimensions. (True|False)\n",
       "5. 3D printing technology has no applications in the medical field. (True|False)\n",
       "\n",
       "Answers:\n",
       "1. True\n",
       "2. False\n",
       "3. True\n",
       "4. False\n",
       "5. False"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(quiz_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_response = chain.run(num_questions=3, quiz_type=\"Open-ended\", quiz_context=\"Art History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Open-ended questions about Art History:\n",
       "\n",
       "Questions:\n",
       "1. Who painted the Mona Lisa?\n",
       "2. What is the significance of the cave paintings in Lascaux, France?\n",
       "3. Describe the style and characteristics of the Impressionist movement.\n",
       "\n",
       "Answers:\n",
       "1. The Mona Lisa was painted by Leonardo da Vinci.\n",
       "2. The cave paintings in Lascaux, France are significant because they provide valuable insights into prehistoric human culture and art.\n",
       "3. The Impressionist movement was characterized by its emphasis on capturing the fleeting effects of light and color in outdoor scenes, using loose brushwork and vibrant colors. Some notable Impressionist artists include Claude Monet, Pierre-Auguste Renoir, and Edgar Degas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(quiz_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes Summarizer App\n",
    "\n",
    "**Presentation:** \n",
    "\n",
    "[building a Notes Summarizer with ChatGPT](https://www.notion.so/building-a-Notes-Summarizer-with-ChatGPT-1793d64631a144978c016d44e0a54ebe?pvs=21)\n",
    "\n",
    "- Exercise/Lab:\n",
    "    \n",
    "    [build a simple notes summarizer app with ChatGPT](https://www.notion.so/build-a-simple-notes-summarizer-app-with-ChatGPT-5af7f8435d81476c87da5d6e5af2e2d7?pvs=21)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The kickoff meeting for the new project, CodeName X, was held on July 23, 2023, with John Doe, Jane Smith, Michael Brown, and Lisa Johnson in attendance. The project aims to develop a new AI model to improve product capabilities and is estimated to take 18 months. Jane Smith discussed resources, such as the development team and AI training facilities, and potential consulting. Michael Brown presented the development plan, with an exploratory phase followed by a focused development phase. Lisa Johnson emphasized good communication and suggested the Agile methodology to manage the project. Next steps include a project brief from John, consultant search by Jane, a sandbox setup for the development team by Michael, and a project planning meeting by Lisa next week.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful research assistant\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "text = \"\"\"Title: Project Launch Meeting\n",
    "\n",
    "Date: July 23, 2023\n",
    "\n",
    "Attendees: John Doe, Jane Smith, Michael Brown, Lisa Johnson\n",
    "\n",
    "Summary: \n",
    "\n",
    "Today we held the kickoff meeting for our new project, CodeName X. The team is very excited to get started. John Doe gave an overview of the project, explaining that the goal is to develop a new AI model that will significantly improve our product's capabilities. The estimated timeline for the project is 18 months, but John stressed that this is a rough estimate and will likely be refined as we delve deeper into the project.\n",
    "\n",
    "Jane Smith spoke about the resources we have at our disposal, including a robust development team and state-of-the-art AI training facilities. She also mentioned the possibility of bringing in some external consultants for specific tasks, which was met with approval from the rest of the team.\n",
    "\n",
    "Michael Brown, our lead developer, gave a technical overview of how we might approach the development of the AI model. He proposed a two-stage process: an initial exploratory phase to investigate different methods, followed by a focused development phase where we will construct and fine-tune the final model. \n",
    "\n",
    "Lisa Johnson talked about project management and highlighted the importance of maintaining good communication throughout the project. She suggested using Agile methodology to manage the project, which the team agreed upon.\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "John will send out a project brief by the end of this week. Jane will look into potential consultants we might want to bring on board. Michael will begin setting up a sandbox for the development team to use during the exploratory phase. Lisa will set up the project in our project management tool and will schedule a project planning meeting for next week.\n",
    "\n",
    "\"\"\"\n",
    "get_response(f\"Summarize this text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok , great we can get a basic summary easy using just ChatGPT, but how about if we want to be able to specify different types of summaries? \n",
    "What if the contents we want to summarize are bigger than the context length of our model?\n",
    "\n",
    "Let's address these issues by using langchain for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With langchain, summarization is as simple as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The project kickoff meeting for CodeName X took place on July 23, 2023. The team aims to develop a new AI model to enhance the product's capabilities. The estimated timeline is 18 months but subject to refinement. The available resources and the possibility of external consultants were discussed. The lead developer proposed a two-stage development process. Agile methodology will be used for project management. Next steps include sending out a project brief, considering consultants, setting up a sandbox, and scheduling a project planning meeting.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = TextLoader(\"./notes.txt\").load()\n",
    "llm = ChatOpenAI()\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as always, we would like to go beyond, why not set up a prompt template to allow for some customization of the summaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Project kickoff meeting held for new project, CodeName X\\n- John Doe overviewed project goal of developing new AI model to improve product capabilities\\n- Estimated timeline for project is 18 months, subject to refinement\\n- Jane Smith discussed available resources and potential for external consultants\\n- Michael Brown proposed two-stage process for AI model development\\n- Lisa Johnson emphasized importance of communication and suggested Agile methodology for project management\\n- Next steps include sending project brief, researching consultants, setting up development sandbox, and scheduling project planning meeting.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following text:\n",
    "\n",
    "{text}\n",
    "\n",
    "The summary should be in this style: {style}.\n",
    "Let's think step by step.\n",
    "\n",
    "SUMMARY:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template,\n",
    "                        input_variables=[\"text\", \"style\"])\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "chain.run({\"input_documents\": docs, \"style\": \"bullet points\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's wrap this into a streamlit app to allow for a nice looking user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 17:00:12.745 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/homebrew/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2023-10-19 17:00:12.746 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# This app should be run in a separate .py file, it is here for\n",
    "# presentation purposes only\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "import streamlit as st\n",
    "\n",
    "def load_text_file(text_file):\n",
    "    docs = TextLoader(text_file).load()\n",
    "    return docs\n",
    "\n",
    "\n",
    "def setup_summarization_chain(docs):\n",
    "    llm = ChatOpenAI()\n",
    "    prompt_template = \"\"\"Write a concise summary of the following text:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    The summary should be in this style: {style}.\n",
    "    Let's think step by step.\n",
    "\n",
    "    SUMMARY:\"\"\"\n",
    "\n",
    "    PROMPT = PromptTemplate(template=prompt_template,\n",
    "                            input_variables=[\"text\", \"style\"])\n",
    "\n",
    "    chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "    return chain\n",
    "\n",
    "\n",
    "def summarize_content(docs, chain, summary_option):\n",
    "    \"\"\"\n",
    "    Runs the summarization chain with \n",
    "    the option specificed by the user.\n",
    "    \"\"\"\n",
    "    summary = chain.run({\"input_documents\": docs, \"style\": summary_option})\n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "st.title('Notes Summarizer using ChatGPT')\n",
    "uploaded_file = st.text_input(\"Choose a .txt file\")\n",
    "\n",
    "summary_option = st.selectbox(\n",
    "    'How do you want your summary?',\n",
    "    ('Simple', 'Bullet points', 'Introduction, Argument, Conclusion', 'Custom Summary')\n",
    ")\n",
    "\n",
    "if uploaded_file!=\"\":\n",
    "    docs = load_text_file(uploaded_file)\n",
    "    chain = setup_summarization_chain(docs)\n",
    "\n",
    "if st.button('Summarize'):\n",
    "    st.session_state.summary = summarize_content(docs, chain, summary_option)\n",
    "\n",
    "if 'summary' in st.session_state and st.session_state.summary:\n",
    "    st.write('Your Summary: ', st.session_state.summary)\n",
    "    if st.button('Download Summary'):\n",
    "        with open('summary.txt', 'w') as f:\n",
    "            f.write(st.session_state.summary)\n",
    "        \n",
    "        st.write(\"Your summary was downloaded to summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break (10 minutes)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notes summarize example](https://platform.openai.com/examples/default-meeting-notes-summarizer)\n",
    "\n",
    "You will be provided with meeting notes, and your task is to summarize the meeting as follows:\n",
    "\n",
    "-Overall summary of discussion\n",
    "-Action items (what needs to be done and who is doing it)\n",
    "-If applicable, a list of topics that need to be discussed more fully in the next meeting.\n",
    "USER\n",
    "Meeting Date: March 5th, 2050\n",
    "Meeting Time: 2:00 PM\n",
    "Location: Conference Room 3B, Intergalactic Headquarters\n",
    "\n",
    "Attendees:\n",
    "- Captain Stardust\n",
    "- Dr. Quasar\n",
    "- Lady Nebula\n",
    "- Sir Supernova\n",
    "- Ms. Comet\n",
    "\n",
    "Meeting called to order by Captain Stardust at 2:05 PM\n",
    "\n",
    "1. Introductions and welcome to our newest team member, Ms. Comet\n",
    "\n",
    "2. Discussion of our recent mission to Planet Zog\n",
    "- Captain Stardust: \"Overall, a success, but communication with the Zogians was difficult. We need to improve our language skills.\"\n",
    "- Dr. Quasar: \"Agreed. I'll start working on a Zogian-English dictionary right away.\"\n",
    "- Lady Nebula: \"The Zogian food was out of this world, literally! We should consider having a Zogian food night on the ship.\"\n",
    "\n",
    "3. Addressing the space pirate issue in Sector 7\n",
    "- Sir Supernova: \"We need a better strategy for dealing with these pirates. They've already plundered three cargo ships this month.\"\n",
    "- Captain Stardust: \"I'll speak with Admiral Starbeam about increasing patrols in that area.\n",
    "- Dr. Quasar: \"I've been working on a new cloaking technology that could help our ships avoid detection by the pirates. I'll need a few more weeks to finalize the prototype.\"\n",
    "\n",
    "4. Review of the annual Intergalactic Bake-Off\n",
    "- Lady Nebula: \"I'm happy to report that our team placed second in the competition! Our Martian Mud Pie was a big hit!\"\n",
    "- Ms. Comet: \"Let's aim for first place next year. I have a secret recipe for Jupiter Jello that I think could be a winner.\"\n",
    "\n",
    "5. Planning for the upcoming charity fundraiser\n",
    "- Captain Stardust: \"We need some creative ideas for our booth at the Intergalactic Charity Bazaar.\"\n",
    "- Sir Supernova: \"How about a 'Dunk the Alien' game? We can have people throw water balloons at a volunteer dressed as an alien.\"\n",
    "- Dr. Quasar: \"I can set up a 'Name That Star' trivia game with prizes for the winners.\"\n",
    "- Lady Nebula: \"Great ideas, everyone. Let's start gathering the supplies and preparing the games.\"\n",
    "\n",
    "6. Upcoming team-building retreat\n",
    "- Ms. Comet: \"I would like to propose a team-building retreat to the Moon Resort and Spa. It's a great opportunity to bond and relax after our recent missions.\"\n",
    "- Captain Stardust: \"Sounds like a fantastic idea. I'll check the budget and see if we can make it happen.\"\n",
    "\n",
    "7. Next meeting agenda items\n",
    "- Update on the Zogian-English dictionary (Dr. Quasar)\n",
    "- Progress report on the cloaking technology (Dr. Quasar)\n",
    "- Results of increased patrols in Sector 7 (Captain Stardust)\n",
    "- Final preparations for the Intergalactic Charity Bazaar (All)\n",
    "\n",
    "Meeting adjourned at 3:15 PM. Next meeting scheduled for March 19th, 2050 at 2:00 PM in Conference Room 3B, Intergalactic Headquarters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly_env",
   "language": "python",
   "name": "oreilly_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
