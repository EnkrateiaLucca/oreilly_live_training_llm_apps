{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-07-24-10-52-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple QA System for Chatting with a PDF\n",
    "\n",
    "This part of the training will be mostly hands on with the code for building the qa PDF system with langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500, chunk_overlap = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './persist_directory/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./assets-resources/llm_paper_know_dont_know.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(pdf_path)\n",
    "pdf_doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(pdf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(all_splits, embedding=embedding,\\\n",
    "        persist_directory=persist_directory)\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/conversational_retrieval/base.py:379: UserWarning: `ChatVectorDBChain` is deprecated - please use `from langchain.chains import ConversationalRetrievalChain`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pdf_qa = ChatVectorDBChain.from_llm(ChatOpenAI(temperature=0,\\\n",
    "    model_name=\"gpt-3.5-turbo\"), vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the main contributions of this paper with regards to self-knowledge in LLMs?',\n",
       " 'chat_history': [],\n",
       " 'answer': 'The main contribution of this paper is that it highlights the existing disparity between the self-knowledge of language models (LLMs) and human self-knowledge. It emphasizes the need for further research to enhance the ability of LLMs to understand their own limitations and unknowns. The paper suggests that by improving the self-knowledge of LLMs, it will lead to more accurate and reliable responses, ultimately having a positive impact on their applications in diverse fields.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the main contributions of this paper with regards to self-knowledge in LLMs?\"\n",
    "pdf_qa({\"question\": query, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the Q&A app for pdfs in `qa_pdf.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the app with:\n",
    "\n",
    "`streamlit run qa_pdf.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-10-19-17-09-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Long context issue in LLMs](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "\n",
    "Long Context. One of the main drawbacks of Transformerbased language models is the context length is limited due to the involved quadratic computational costs in both time\n",
    "and memory. Meanwhile, there is an increasing demand\n",
    "for LLM applications with long context windows, such as\n",
    "in PDF processing and story writing [217]. ChatGPT has\n",
    "recently released an updated variant with a context window\n",
    "size of up to 16K tokens, which is much longer than the\n",
    "initial one, i.e., 4K tokens. Additionally, GPT-4 was launched\n",
    "with variants with context window of 32K tokens [46]. Next,\n",
    "we discuss two important factors that support long context\n",
    "modeling for LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb \n",
    "Below are notebook from openai cookbook on these topics of search and embeddings:\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Get_embeddings.ipynb\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Code_search.ipynb\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_Wikipedia_articles_for_search.ipynb\n",
    "- https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "- [In-context learning abilities of ChatGPT models](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "- [Issue with long context](https://arxiv.org/pdf/2303.18223.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly_env",
   "language": "python",
   "name": "oreilly_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
