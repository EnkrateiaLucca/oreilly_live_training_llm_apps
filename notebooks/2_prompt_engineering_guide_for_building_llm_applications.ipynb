{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Presentation:** \n",
    "\n",
    "# Introduction to Prompt Engineering and the ChatGPT API\n",
    "\n",
    "- Prompt basics \n",
    "- Introduction to the ChatGPT API\n",
    "- Prompt engineering guide\n",
    "- Best practices for writing effective prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Basics\n",
    "\n",
    "A prompt is a piece of text that conveys to a LLM what the user wants. What the user wants can be many things like:\n",
    "\n",
    "- Asking a question\n",
    "- Giving an instruction\n",
    "- Etc...\n",
    "\n",
    "The key components of a prompt are:\n",
    "1. Task description: where you describe what you want\n",
    "2. Input data: data the model has not seem to illustrate what you need\n",
    "3. Context information: background info on what you are requesting, the data you are providing etc...\n",
    "4. Prompt style: its how you ask the thing to the model and that can greatly influence its performance, for example asking the model [\"Let's think step by step\" can boost reasoning performance](https://arxiv.org/pdf/2201.11903.pdf).\n",
    "\n",
    "[Prompts can also be seen as a form of programming that can customize the outputs and interactions with an LLM.](https://ar5iv.labs.arxiv.org/html/2302.11382#:~:text=prompts%20are%20also%20a%20form%20of%20programming%20that%20can%20customize%20the%20outputs%20and%20interactions%20with%20an%20llm.)\n",
    "\n",
    "One way I like to think about prompts, is as tools that rearrange the weights (probabilities) in the LLM text representation space, to allow you access to a particular sub-universe within the embedding space of the LLM. \n",
    "\n",
    "<span style=\"color: red\">Reconsider the technicalities of wording it like this </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import squarify\n",
    "\n",
    "# Sample data (sizes of rectangles)\n",
    "sizes = [500, 300, 200, 100]\n",
    "\n",
    "# Labels for the rectangles (optional)\n",
    "labels = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "# Plotting the treemap\n",
    "plt.subplot(1,3,1)\n",
    "squarify.plot(sizes=sizes, label=labels, alpha=0.8, color=[\"red\", \"green\", \"blue\", \"grey\"])\n",
    "plt.title(\"LLM Representation Space\")\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot([], [])\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Draw an arrow from point (2, 1) to point (4, 3)\n",
    "plt.annotate('', xy=(10, 5), xytext=(0, 5),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),ha=\"center\", va=\"top\")\n",
    "plt.subplot(1,3,3)\n",
    "sizes = [200, 600, 100, 400]\n",
    "\n",
    "# Labels for the rectangles (optional)\n",
    "labels = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# Plotting the treemap\n",
    "squarify.plot(sizes=sizes, label=labels, alpha=0.8, color=[\"red\", \"green\", \"blue\", \"grey\"])\n",
    "plt.title(\"LLM Representation Space After a Prompt\")\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to ChatGPT API\n",
    "\n",
    "- Where does ChatGPT fit into this chaotic universe?\n",
    "- The ChatGPT API (what’s the deal?)\n",
    "- How to use it, basics, parameters, simple examples, etc…."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request body for the CHATGPT API involves many parameters, but let's focus on the following:\n",
    "\n",
    "- model: ID of the model to use.\n",
    "- messages: a list of messages comprising the conversation up to that point\n",
    "- temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "- n: number of chat completion choices to generate for each input message\n",
    "- max_tokens: the maximum number of tokens to generate in the chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7ormkugOIAJ9zqysAgn7T1jIQZcCq at 0x7f3560089790> JSON: {\n",
       "  \"id\": \"chatcmpl-7ormkugOIAJ9zqysAgn7T1jIQZcCq\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1692357506,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The meaning of life is a deeply philosophical and subjective question that has been pondered by humans for centuries. Different cultures, religions, and individuals may have varying perspectives on this matter. From a more existential perspective, the meaning of life is not inherently predetermined or universal. It is up to each individual to find their own sense of purpose and meaning in life. This can involve exploring personal passions, building meaningful relationships, making a positive impact on the world, or pursuing spiritual growth. Ultimately, the meaning of\"\n",
       "      },\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 34,\n",
       "    \"completion_tokens\": 100,\n",
       "    \"total_tokens\": 134\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install openai\n",
    "\n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import openai\n",
    "\n",
    "\n",
    "prompt = \"What is the meaning of life?\"\n",
    "openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                             messages=\n",
    "                             [\n",
    "                                 {\"role\": \"system\", \"content\": \"You are a savy guru with knowledge about existence and the secrets of life.\"},\n",
    "                                 {\"role\": \"user\", \"content\": prompt}   \n",
    "                             ],\n",
    "                             max_tokens=100,\n",
    "                             temperature=0.9,\n",
    "                             n = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response object returned is a **chat completion object**, whose properties are as follows:\n",
    "\n",
    "\n",
    "- `id`\n",
    "  - string\n",
    "  - A unique identifier for the chat completion.\n",
    "\n",
    "- `object`\n",
    "  - string\n",
    "  - The object type, which is always chat.completion.\n",
    "\n",
    "- `created`\n",
    "  - integer\n",
    "  - A unix timestamp of when the chat completion was created.\n",
    "\n",
    "- `model`\n",
    "  - string\n",
    "  - The model used for the chat completion.\n",
    "\n",
    "- `choices`\n",
    "  - array\n",
    "  - A list of chat completion choices. Can be more than one if n is greater than 1.\n",
    "\n",
    "    - `index`\n",
    "        - integer\n",
    "        - The index of the choice in the list of choices.\n",
    "\n",
    "    - `message`\n",
    "      - object\n",
    "      - A chat completion message generated by the model.\n",
    "\n",
    "\n",
    "    - `finish_reason`\n",
    "      - string\n",
    "      - The reason the model stopped generating tokens (reached max length, called function etc...)\n",
    "\n",
    "- `usage`\n",
    "    - object\n",
    "    - Usage statistics for the completion request.\n",
    "\n",
    "      - `prompt_tokens`\n",
    "        - integer\n",
    "        - Number of tokens in the prompt.\n",
    "\n",
    "    - `completion_tokens`\n",
    "      - integer\n",
    "      - Number of tokens in the generated completion.\n",
    "\n",
    "    - `total_tokens`\n",
    "      - integer\n",
    "      - Total number of tokens used in the request (prompt + completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: chatcmpl-7ekXqif2CqRsv76vBnMgUCZHT2Y0g\n",
      "***\n",
      "object: chat.completion\n",
      "***\n",
      "created: 1689946394\n",
      "***\n",
      "model: gpt-3.5-turbo-0613\n",
      "***\n",
      "choices: [<OpenAIObject at 0x7f409df7a480> JSON: {\n",
      "  \"index\": 0,\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Why don't scientists trust atoms?\\nBecause they make up everything!\"\n",
      "  },\n",
      "  \"finish_reason\": \"stop\"\n",
      "}]\n",
      "***\n",
      "usage: {\n",
      "  \"prompt_tokens\": 24,\n",
      "  \"completion_tokens\": 13,\n",
      "  \"total_tokens\": 37\n",
      "}\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "# another example\n",
    "import openai\n",
    "\n",
    "def llm_model(prompt_question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and\\\n",
    "            programming assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "prompt = \"Tell me a joke\"\n",
    "response = llm_model(prompt)\n",
    "for r in response.keys():\n",
    "    print(f\"{r}: {response[r]}\")\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Guide\n",
    "\n",
    "What is prompt engineering?\n",
    "\n",
    "Prompt engineering is a reference to a discipline concerned with stablishing the rules for obtaining the most deterministic outputs possible from a LLM by employing engineering techniques and protocols to enture reproducibility and consistency.\n",
    "\n",
    "***In a simplified way, prompt engineering is the means by which LLMs can be programmed through prompting.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic goal of prompt engineering is designing appropriate inputs for prompting methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Techniques\n",
    "\n",
    "Now, let's walk through a simplified guide of prompt engineering techniques:\n",
    "\n",
    "- [Zero-shot Prompting](https://www.promptingguide.ai/techniques/zeroshot#:~:text=Large%20LLMs%20today,examples%20we%20used%3A)\n",
    "- [Few-shot Prompting](https://www.promptingguide.ai/techniques/fewshot#:~:text=few-shot%20prompting%20can%20be%20used%20as%20a%20technique%20to%20enable%20in-context%20learning%20where%20we%20provide%20demonstrations%20in%20the%20prompt%20to%20steer%20the%20model%20to%20better%20performance)\n",
    "- [Chain-of-Thought](https://www.promptingguide.ai/techniques/cot#:~:text=introduced%20in%20wei%20et%20al.%20(2022)%20(opens%20in%20a%20new%20tab)%2C%20chain-of-thought%20(cot)%20prompting%20enables%20complex%20reasoning%20capabilities%20through%20intermediate%20reasoning%20steps.%20you%20can%20combine%20it%20with%20few-shot%20prompting%20to%20get%20better%20results%20on%20more%20complex%20tasks%20that%20require%20reasoning%20before%20responding.)\n",
    "- [Self-consistency](https://www.promptingguide.ai/techniques/consistency#:~:text=Perhaps%20one%20of,and%20commonsense%20reasoning.)\n",
    "- [Generate Knowledge](https://www.promptingguide.ai/techniques/knowledge#:~:text=LLMs%20continue%20to,as%20commonsense%20reasoning%3F)\n",
    "- [Tree of thoughts (ToT)](https://www.promptingguide.ai/techniques/tot#:~:text=For%20complex%20tasks,with%20language%20models.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot Prompting\n",
    "\n",
    "[Zero-shot prompting](https://arxiv.org/pdf/2109.01652.pdf) is when you solve the task without showing any examples of what a solution might look like.\n",
    "\n",
    "For example consider a prompt like:\n",
    "\n",
    "```\n",
    "Classify the sentiment in this sentence as negative or positive:\n",
    "Text: I will go to a vacation\n",
    "Sentiment:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "prompt = \"\"\"Classify the sentiment in this sentence as negative or positive:\n",
    "Text: Ellie thinks Lucas is a freaking genius.\n",
    "Sentiment:\"\"\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a few more like:\n",
    "\n",
    "```\n",
    "What is the capital of Canada?\n",
    "Answer:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Canada is Ottawa.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the capital of Canada?\\nAnswer:\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so on and so forth, one can use this as the first try at a model to see what kinds of tasks that LLM can already solve out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot Prompting\n",
    "\n",
    "As the complexity of a task increases, you might need to provide information in the form of examples to the LLM.\n",
    "\n",
    "**Few-shot Prompting** is a prompting technique where you show a few examples of what a solution might look like.\n",
    "\n",
    "THe goal is to enable what is called 'in-context learning' where the model improves by learning contextual information about the task at hand.\n",
    "\n",
    "We do that by giving demonstrations that will serve as conditionning for subsequent examples where we would like the model to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The children were so excited to see the ice cream truck that they started farduddling in anticipation.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the example was taken from here: https://www.promptingguide.ai/techniques/fewshot\n",
    "import openai\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "prompt = \"\"\"\n",
    "A \"whatpu\" is a small, furry animal native to Tanzania. An example of a sentence that uses\n",
    "the word whatpu is:\n",
    "We were traveling in Africa and we saw these very cute whatpus.\n",
    "To do a \"farduddle\" means to jump up and down really fast. An example of a sentence that uses\n",
    "the word farduddle is:\n",
    "\"\"\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought\n",
    "\n",
    "This is a prompting technique where we induce step-by-step reasoning and planning within the prompt to enhance performance of the model.\n",
    "\n",
    "According to [Wei et al. (2022)](https://arxiv.org/abs/2201.11903), chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If Sally is 5 years younger than me and I am 17 years old, Sally is 17-5=12 years old. If Jack is 2 years older than Sally, Jack is 12+2=14 years old. The answer is 14 years old.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the example was taken from here: https://www.promptingguide.ai/techniques/fewshot\n",
    "import openai\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "prompt = \"\"\"\n",
    "Q: I have one sister and one brother. I am 20 years of age. My sister is 5 years older and my brother 2 years younger than my sister.\n",
    "How old is my brother?\n",
    "A: If I am 20 years of age and my sister is 5 years older, my sister is 20+5=25 years old. If my brother is 2 years younger than my sister, my brother is 25-2=23 years old. The answer is 23 years old.\n",
    "\n",
    "Q: I have 2 friends, Jack and Sally. Jack is 2 years older than Sally. Sally is 5 years younger than me. I am 17 years old. How old is Jack?\n",
    "A:\n",
    "\"\"\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine few-shot prompting with chain-of-thought to get better results on highly complex tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://www.promptingguide.ai/techniques/cot \n",
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-consistency\n",
    "\n",
    "You use few shot prompting and chain of thoughts to sample a bunch of reasoning paths and then use generations to select the most consistent answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olivia initially had $23. She bought 5 bagels for $3 each, so she spent 5 * $3 = $15 on bagels. Now she has $23 - $15 = $8 left. The answer is $8.\n",
      "Olivia has $23. She spent 5 * $3 = $15 on bagels. So she has $23 - $15 = $8 left. The answer is $8.\n",
      "Olivia initially has $23. She spent $3 per bagel, so in total she spent 5 * $3 = $15 on bagels.\n",
      "Now, she has $23 - $15 = $8 left. The answer is $8.\n",
      "Olivia has $23 and each bagel costs $3. She bought 5 bagels, so she spent 5 * $3 = $15. \n",
      "Therefore, Olivia has $23 - $15 = $8 left. The answer is $8.\n",
      "Olivia has $23. She spent 5 * $3 = $15 on bagels. Therefore, she has $23 - $15 = $8 left. The answer is $8.\n"
     ]
    }
   ],
   "source": [
    "# source: https://arxiv.org/pdf/2203.11171.pdf\n",
    "few_shot_CoT_prompt = \"\"\"\n",
    "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
    "there will be 21 trees. How many trees did the grove workers plant today?\n",
    "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
    "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
    "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
    "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
    "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
    "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
    "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
    "did Jason give to Denny?\n",
    "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
    "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
    "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
    "he have now?\n",
    "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
    "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
    "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
    "monday to thursday. How many computers are now in the server room?\n",
    "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
    "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
    "The answer is 29.\n",
    "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
    "golf balls did he have at the end of wednesday?\n",
    "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
    "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
    "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
    "A: \n",
    "\"\"\"\n",
    "\n",
    "n_reasoning_paths = 5\n",
    "answers = []\n",
    "for i in range(n_reasoning_paths):\n",
    "    response = get_response(few_shot_CoT_prompt)\n",
    "    answers.append(response)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Knowledge\n",
    "\n",
    "This technique is about inserting knowledge into the prompt in order to yield better performance, you use the model to generate knowledge about a field, and then use that generated knowledge to improve its performance on a downstream task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In golf, the objective is to complete each hole in as few strokes as possible. The player with the lowest total number of strokes at the end of the round is the winner. It is not about achieving a higher point total than others, but rather achieving the lowest score.', \"Actually, in golf, the objective is to have the lowest score possible. Unlike many other sports, golf uses a stroke-based scoring system where each stroke taken to complete the hole adds one point to the player's score. The player with the lowest overall score at the end of the round is the winner. So, in golf, the goal is to have the fewest points, not the highest.\", 'Actually, in golf, the objective is to achieve the lowest score possible. Each hole is assigned a par score, and the goal is to complete each hole in as few strokes as possible. At the end of the round, the player with the lowest total score is the winner. So, in golf, the lower the score, the better.']\n"
     ]
    }
   ],
   "source": [
    "# source: https://www.promptingguide.ai/techniques/knowledge\n",
    "prompt = \"\"\"Input: Greece is larger than mexico.\n",
    "Knowledge: Greece is approximately 131,957 sq km, while Mexico is approximately 1,964,375 sq km, making Mexico 1,389% larger than Greece.\n",
    "Input: Glasses always fog up.\n",
    "Knowledge: Condensation occurs on eyeglass lenses when water vapor from your sweat, breath, and ambient humidity lands on a cold surface, cools, and then changes into tiny drops of liquid, forming a film that you see as fog. Your lenses will be relatively cool compared to your breath, especially when the outside air is cold.\n",
    "Input: A fish is capable of thinking.\n",
    "Knowledge: Fish are more intelligent than they appear. In many areas, such as memory, their cognitive powers match or exceed those of ’higher’ vertebrates including non-human primates. Fish’s long-term memories help them keep track of complex social relationships.\n",
    "Input: A common effect of smoking lots of cigarettes in one’s lifetime is a higher than normal chance of getting lung cancer.\n",
    "Knowledge: Those who consistently averaged less than one cigarette per day over their lifetime had nine times the risk of dying from lung cancer than never smokers. Among people who smoked between one and 10 cigarettes per day, the risk of dying from lung cancer was nearly 12 times higher than that of never smokers.\n",
    "Input: A rock is the same size as a pebble.\n",
    "Knowledge: A pebble is a clast of rock with a particle size of 4 to 64 millimetres based on the Udden-Wentworth scale of sedimentology. Pebbles are generally considered larger than granules (2 to 4 millimetres diameter) and smaller than cobbles (64 to 256 millimetres diameter).\n",
    "Input: Part of golf is trying to get a higher point total than others.\n",
    "Knowledge:\"\"\"\n",
    "knowledges = []\n",
    "num_knowledges = 3\n",
    "for i in range(num_knowledges):\n",
    "    knowledges.append(get_response(prompt))\n",
    "\n",
    "print(knowledges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We integrate the knowledge to get a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.promptingguide.ai/techniques/knowledge\n",
    "prompt = \"\"\"Question: Part of golf is trying to get a higher point total than others. Yes or No?\n",
    "Knowledge: The objective of golf is to play a set of holes in the least number of strokes. A round of golf typically consists of 18 holes. Each hole is played once in the round on a standard golf course. Each stroke is counted as one point, and the total number of strokes is used to determine the winner of the game.\n",
    "Explain and Answer: \"\"\"\n",
    "\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree of thoughts (ToT)\n",
    "\n",
    "\n",
    "ToT [Long (2023)](https://arxiv.org/pdf/2305.08291.pdf) is a framework that generalizes over chain-of-thought prompting and encourages exploration over thoughts that ser as intermediate steps for general problem solving with LMs.\n",
    "\n",
    "This technique involves a framework where a tree of thoughts is maintained, where a thought here means a coherent sequence of steps that represent moving forward in the solution. The LMs are given the ability to self-evaluate on how intermediate thoughts contribute towards progress solving the problem through a deliberate reasoning process which involves combining this evaluation ability with search algorithms to allow for backtracking and lookahead over the space of possible thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/ToT_framework.png)\n",
    "Image Source: [Yao et el. (2023)](https://arxiv.org/pdf/2305.08291.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many More but That's Enough\n",
    "\n",
    "There are many more prompt engineering techniques that grow in complexity like:\n",
    "- [Retrieval Augmented Generation (RAG)](https://www.promptingguide.ai/techniques/rag)\n",
    "- [Automatic Prompt Engineer](https://www.promptingguide.ai/techniques/ape)\n",
    "- [Active Prompt](https://www.promptingguide.ai/techniques/activeprompt)\n",
    "- [Directional Stimulus Prompting](https://www.promptingguide.ai/techniques/dsp)\n",
    "- [React Prompting](https://www.promptingguide.ai/techniques/react)\n",
    "- [Mulitmodal CoT](https://www.promptingguide.ai/techniques/multimodalcot)\n",
    "- [Graph Prompting](https://www.promptingguide.ai/techniques/graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise/Lab:\n",
    "  - Getting started with prompt engineering using the ChatGPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise/Lab:\n",
    "  - prompt engineering for\n",
    "    - [text summarization](https://www.promptingguide.ai/introduction/examples.en#:~:text=Reasoning-,Text%20Summarization,summarization%20task%20using%20prompts.,-Let's%20say%20you)\n",
    "    - [question answering](https://www.promptingguide.ai/introduction/examples.en#question-answering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Entineering Practical Case Study\n",
    "\n",
    "Now, let's take the concepts and ideas discussed in this lesson, and apply them to an actual problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple example, imagine you want to extract dates from text. You might set up a LLM to do that by first creating a set of examples of phrases with dates, something we can start with ChatGPT itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On January 12th, 2023, Sarah embarked on an exciting journey to explore the vibrant streets of Tokyo, Japan, immersing herself in its rich culture, delicious cuisine, and stunning architecture.',\n",
       " 'On July 15, 2022, our team will be hosting a special event where we will unveil our latest product innovation. Join us at the conference center to witness the future of technology firsthand and discover how this groundbreaking solution will revolutionize your everyday life.',\n",
       " 'On March 15th, 2022, it was announced that the long-awaited sequel to the beloved film would be released on November 25th, 2023, much to the excitement of fans worldwide.',\n",
       " 'On January 15, 2023, our company will be celebrating its 10th anniversary with a grand event showcasing our success and growth over the past decade.',\n",
       " 'On May 17, 2022, the highly anticipated event showcased the latest innovations in technology, bringing together experts and enthusiasts from around the globe.',\n",
       " 'On the sunny afternoon of October 15, 2022, Emily and Daniel embarked on their long-awaited road trip, with excitement radiating from their faces as they navigated the open roads and explored the breathtaking landscapes that unfolded before them.',\n",
       " 'On 25th November 2023, people from all walks of life will gather together to celebrate the spirit of unity and gratitude at the annual Thanksgiving parade.',\n",
       " \"On October 12th, 2023, we will be hosting a grand celebration to commemorate the 50th anniversary of our company's founding.\",\n",
       " 'On August 27, 2021, we will be hosting a special event to celebrate the grand opening of our new store. There will be discounts, giveaways, and live performances throughout the day, so mark your calendars and join us for an unforgettable experience.',\n",
       " 'On December 31st, 2021, we will be celebrating a new year with joy and excitement.',\n",
       " 'On October 15th, 2022, make sure to mark your calendars for the highly anticipated opening ceremony of the annual international film festival, where renowned filmmakers from around the world will gather to showcase their latest cinematic creations.',\n",
       " 'On October 15, 2022, the excitement was palpable at the grand opening of the new art gallery in downtown.',\n",
       " \"On September 15, 2022, Sarah embarked on an adventurous journey to explore the breathtaking landscapes of New Zealand, immersing herself in the stunning beauty of the country's mountains, lakes, and forests.\",\n",
       " 'On April 29, 2022, the highly anticipated sports event will take place, gathering athletes from all over the world to showcase their skills and compete for glory.',\n",
       " 'On the bright and sunny morning of October 13, 2022, as the golden leaves gently fell to the ground, Sarah eagerly set out on her journey to explore the charming streets of Paris, a city she had always dreamt of visiting.',\n",
       " 'On the sunny morning of July 20th, 2023, as the birds chirped merrily outside the window, the young girl eagerly prepared for her first day of school, buzzing with excitement and anticipation for the adventures that awaited her at Oakwood Elementary.',\n",
       " 'On June 10th, 2022, the team will gather for a crucial meeting to discuss the progress of the project and finalize the upcoming milestones.',\n",
       " 'On November 15, 2023, the company will host its annual gala to celebrate another successful year of growth and innovation.',\n",
       " 'On Monday, November 15, 2021, the team successfully delivered the final report to the client, marking the conclusion of a three-month-long project.',\n",
       " 'On a sunny afternoon in July, John and Emily decided to embark on their dream vacation. They packed their bags, boarded the plane, and landed in the majestic city of Paris on July 15th, 2022.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "num_samples = 20\n",
    "phrases_with_dates = []\n",
    "prompt = \"Create a 1 paragraph phrase containing a complete date (day month  and year) anywhere in the text.\"\n",
    "for i in range(num_samples):\n",
    "    phrases_with_dates.append(get_response(prompt))\n",
    "phrases_with_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok perfect! Now that we have this evaluation set, we can set up a simple experiment by first creating a demonstration set with our prompt candidates.\n",
    "\n",
    "We'll begin with a baseline using only zero-shot prompt examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompts = [\"Extract the date from this text as DD-MM-YYYY\", \n",
    "                     \"Extract the formatted date from this text in the format: <DD-MM-YYYY>\",\n",
    "                     \"Fetch the date from this text as DD-MM-YYYY\",\n",
    "                     \"Get the date from this phrase as DD-MM-YYYY\",\n",
    "                     \"Below is a text containing a date. Extract that date in the format: <DD-MM-YYYY>\"\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have our candidates, so let's now test them creating a table with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Extract the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the text is January 12th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Extract the formatted date from this text in t...</td>\n",
       "      <td>The formatted date extracted from the text is:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Fetch the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date in the text is January 12th, 2023. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Get the date from this phrase as DD-MM-YYYY</td>\n",
       "      <td>The date in the phrase is \"January 12th, 2023....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Below is a text containing a date. Extract tha...</td>\n",
       "      <td>The date in the provided text is: 12-01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Extract the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date in the text is \"July 15th, 2022\". Whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Extract the formatted date from this text in t...</td>\n",
       "      <td>15-07-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Fetch the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the text is July 15th, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Get the date from this phrase as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the phrase is July 15th,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Below is a text containing a date. Extract tha...</td>\n",
       "      <td>The date mentioned in the text is: 15-07-2022.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               phrase  \\\n",
       "0   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "1   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "2   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "3   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "4   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "..                                                ...   \n",
       "95  On a sunny afternoon in July, John and Emily d...   \n",
       "96  On a sunny afternoon in July, John and Emily d...   \n",
       "97  On a sunny afternoon in July, John and Emily d...   \n",
       "98  On a sunny afternoon in July, John and Emily d...   \n",
       "99  On a sunny afternoon in July, John and Emily d...   \n",
       "\n",
       "                                               prompt  \\\n",
       "0       Extract the date from this text as DD-MM-YYYY   \n",
       "1   Extract the formatted date from this text in t...   \n",
       "2         Fetch the date from this text as DD-MM-YYYY   \n",
       "3         Get the date from this phrase as DD-MM-YYYY   \n",
       "4   Below is a text containing a date. Extract tha...   \n",
       "..                                                ...   \n",
       "95      Extract the date from this text as DD-MM-YYYY   \n",
       "96  Extract the formatted date from this text in t...   \n",
       "97        Fetch the date from this text as DD-MM-YYYY   \n",
       "98        Get the date from this phrase as DD-MM-YYYY   \n",
       "99  Below is a text containing a date. Extract tha...   \n",
       "\n",
       "                                             response  \n",
       "0   The date mentioned in the text is January 12th...  \n",
       "1   The formatted date extracted from the text is:...  \n",
       "2   The date in the text is January 12th, 2023. Th...  \n",
       "3   The date in the phrase is \"January 12th, 2023....  \n",
       "4        The date in the provided text is: 12-01-2023  \n",
       "..                                                ...  \n",
       "95  The date in the text is \"July 15th, 2022\". Whe...  \n",
       "96                                         15-07-2022  \n",
       "97  The date mentioned in the text is July 15th, 2...  \n",
       "98  The date mentioned in the phrase is July 15th,...  \n",
       "99     The date mentioned in the text is: 15-07-2022.  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for phrase in phrases_with_dates:\n",
    "    for prompt in zero_shot_prompts:\n",
    "        response = get_response(prompt + \" \" + phrase)\n",
    "        data.append([phrase, prompt, response])\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data=data, columns=['phrase','prompt', 'response'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Extract the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the text is January 12th...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Extract the formatted date from this text in t...</td>\n",
       "      <td>The formatted date extracted from the text is:...</td>\n",
       "      <td>12-01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Fetch the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date in the text is January 12th, 2023. Th...</td>\n",
       "      <td>12-01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Get the date from this phrase as DD-MM-YYYY</td>\n",
       "      <td>The date in the phrase is \"January 12th, 2023....</td>\n",
       "      <td>12-01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Below is a text containing a date. Extract tha...</td>\n",
       "      <td>The date in the provided text is: 12-01-2023</td>\n",
       "      <td>12-01-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Extract the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date in the text is \"July 15th, 2022\". Whe...</td>\n",
       "      <td>15-07-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Extract the formatted date from this text in t...</td>\n",
       "      <td>15-07-2022</td>\n",
       "      <td>15-07-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Fetch the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the text is July 15th, 2...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Get the date from this phrase as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the phrase is July 15th,...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Below is a text containing a date. Extract tha...</td>\n",
       "      <td>The date mentioned in the text is: 15-07-2022.</td>\n",
       "      <td>15-07-2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               phrase  \\\n",
       "0   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "1   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "2   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "3   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "4   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "..                                                ...   \n",
       "95  On a sunny afternoon in July, John and Emily d...   \n",
       "96  On a sunny afternoon in July, John and Emily d...   \n",
       "97  On a sunny afternoon in July, John and Emily d...   \n",
       "98  On a sunny afternoon in July, John and Emily d...   \n",
       "99  On a sunny afternoon in July, John and Emily d...   \n",
       "\n",
       "                                               prompt  \\\n",
       "0       Extract the date from this text as DD-MM-YYYY   \n",
       "1   Extract the formatted date from this text in t...   \n",
       "2         Fetch the date from this text as DD-MM-YYYY   \n",
       "3         Get the date from this phrase as DD-MM-YYYY   \n",
       "4   Below is a text containing a date. Extract tha...   \n",
       "..                                                ...   \n",
       "95      Extract the date from this text as DD-MM-YYYY   \n",
       "96  Extract the formatted date from this text in t...   \n",
       "97        Fetch the date from this text as DD-MM-YYYY   \n",
       "98        Get the date from this phrase as DD-MM-YYYY   \n",
       "99  Below is a text containing a date. Extract tha...   \n",
       "\n",
       "                                             response        date  \n",
       "0   The date mentioned in the text is January 12th...        None  \n",
       "1   The formatted date extracted from the text is:...  12-01-2023  \n",
       "2   The date in the text is January 12th, 2023. Th...  12-01-2023  \n",
       "3   The date in the phrase is \"January 12th, 2023....  12-01-2023  \n",
       "4        The date in the provided text is: 12-01-2023  12-01-2023  \n",
       "..                                                ...         ...  \n",
       "95  The date in the text is \"July 15th, 2022\". Whe...  15-07-2022  \n",
       "96                                         15-07-2022  15-07-2022  \n",
       "97  The date mentioned in the text is July 15th, 2...        None  \n",
       "98  The date mentioned in the phrase is July 15th,...        None  \n",
       "99     The date mentioned in the text is: 15-07-2022.  15-07-2022  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "# parse a text response to extract a date formatted as DD-MM-YYYY\n",
    "def extract_date(text):\n",
    "    \"\"\"Date parser\"\"\"\n",
    "    # regex pattern for date\n",
    "    date_pattern = r\"(\\d{1,2})-(\\d{1,2})-(\\d{4})\"\n",
    "    # extract date from text\n",
    "    date = re.search(date_pattern, text)\n",
    "    # return date\n",
    "    return date.group(0) if date else None\n",
    "\n",
    "# apply the function to the 'response' column of the dataframe df\n",
    "df['date'] = df['response'].apply(extract_date)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have some results for the dates that were parsed, we need a way to measure performance so we can compare how well they did. In this case, we'll consider a point for the score of the prompt if a date was properly extracted after running the `extract_date()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>date</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Extract the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the text is January 12th...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Extract the formatted date from this text in t...</td>\n",
       "      <td>The formatted date extracted from the text is:...</td>\n",
       "      <td>12-01-2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Fetch the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date in the text is January 12th, 2023. Th...</td>\n",
       "      <td>12-01-2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Get the date from this phrase as DD-MM-YYYY</td>\n",
       "      <td>The date in the phrase is \"January 12th, 2023....</td>\n",
       "      <td>12-01-2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On January 12th, 2023, Sarah embarked on an ex...</td>\n",
       "      <td>Below is a text containing a date. Extract tha...</td>\n",
       "      <td>The date in the provided text is: 12-01-2023</td>\n",
       "      <td>12-01-2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Extract the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date in the text is \"July 15th, 2022\". Whe...</td>\n",
       "      <td>15-07-2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Extract the formatted date from this text in t...</td>\n",
       "      <td>15-07-2022</td>\n",
       "      <td>15-07-2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Fetch the date from this text as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the text is July 15th, 2...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Get the date from this phrase as DD-MM-YYYY</td>\n",
       "      <td>The date mentioned in the phrase is July 15th,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>On a sunny afternoon in July, John and Emily d...</td>\n",
       "      <td>Below is a text containing a date. Extract tha...</td>\n",
       "      <td>The date mentioned in the text is: 15-07-2022.</td>\n",
       "      <td>15-07-2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               phrase  \\\n",
       "0   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "1   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "2   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "3   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "4   On January 12th, 2023, Sarah embarked on an ex...   \n",
       "..                                                ...   \n",
       "95  On a sunny afternoon in July, John and Emily d...   \n",
       "96  On a sunny afternoon in July, John and Emily d...   \n",
       "97  On a sunny afternoon in July, John and Emily d...   \n",
       "98  On a sunny afternoon in July, John and Emily d...   \n",
       "99  On a sunny afternoon in July, John and Emily d...   \n",
       "\n",
       "                                               prompt  \\\n",
       "0       Extract the date from this text as DD-MM-YYYY   \n",
       "1   Extract the formatted date from this text in t...   \n",
       "2         Fetch the date from this text as DD-MM-YYYY   \n",
       "3         Get the date from this phrase as DD-MM-YYYY   \n",
       "4   Below is a text containing a date. Extract tha...   \n",
       "..                                                ...   \n",
       "95      Extract the date from this text as DD-MM-YYYY   \n",
       "96  Extract the formatted date from this text in t...   \n",
       "97        Fetch the date from this text as DD-MM-YYYY   \n",
       "98        Get the date from this phrase as DD-MM-YYYY   \n",
       "99  Below is a text containing a date. Extract tha...   \n",
       "\n",
       "                                             response        date  scores  \n",
       "0   The date mentioned in the text is January 12th...        None       0  \n",
       "1   The formatted date extracted from the text is:...  12-01-2023       1  \n",
       "2   The date in the text is January 12th, 2023. Th...  12-01-2023       1  \n",
       "3   The date in the phrase is \"January 12th, 2023....  12-01-2023       1  \n",
       "4        The date in the provided text is: 12-01-2023  12-01-2023       1  \n",
       "..                                                ...         ...     ...  \n",
       "95  The date in the text is \"July 15th, 2022\". Whe...  15-07-2022       1  \n",
       "96                                         15-07-2022  15-07-2022       1  \n",
       "97  The date mentioned in the text is July 15th, 2...        None       0  \n",
       "98  The date mentioned in the phrase is July 15th,...        None       0  \n",
       "99     The date mentioned in the text is: 15-07-2022.  15-07-2022       1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column that is 1 if the date value is not None or 0 otherwise\n",
    "df['scores'] = df['date'].apply(lambda x: 1 if x is not None else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Extract the formatted date from this text in the format: &lt;DD-MM-YYYY&gt;</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Below is a text containing a date. Extract that date in the format: &lt;DD-MM-YYYY&gt;</th>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extract the date from this text as DD-MM-YYYY</th>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Get the date from this phrase as DD-MM-YYYY</th>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fetch the date from this text as DD-MM-YYYY</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    scores\n",
       "prompt                                                    \n",
       "Extract the formatted date from this text in th...   100.0\n",
       "Below is a text containing a date. Extract that...    95.0\n",
       "Extract the date from this text as DD-MM-YYYY         80.0\n",
       "Get the date from this phrase as DD-MM-YYYY           80.0\n",
       "Fetch the date from this text as DD-MM-YYYY           40.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by prmopts creating an accuracy column that is the result of summing over the scores and dividing by 20\n",
    "# then sort by accuracy\n",
    "df_performance = df.groupby('prompt').agg({'scores': 'sum'}).sort_values(by='scores', ascending=False)\n",
    "df_performance[\"scores\"] = (df_performance[\"scores\"] / num_samples)*100\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! There we have it, our first results! The way to evolve this approach would be to test on a harder test set and if we don't get good results, we try better prompting strategies like few-shot, self-consistency, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Slightly More Complex Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we'll look at desgining a simple prompt engineering experiment to find the best prompt to generate an intuitive and simple explanation of a concept.\n",
    "\n",
    "The idea is that, given a concept, or piece of information we would like to understand, the model should output a simple one paragraph explanation giving all the necessary context and information to allow the user to grasp the concept at hand.\n",
    "\n",
    "Let's start by creating a few prompt candidates, in the beggining its always a good idea to come up with a few prompts yourself, and preferably zero-shot examples which would be the baseline upon which we'll improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_candidates = [\"Explain this concept in simple terms\", \n",
    "                     \"Explain the following concept:\", \n",
    "                     \"Explain this:\", \n",
    "                     \"Break down this concept for a beginner:\",\n",
    "                    \"Can you simplify the explanation of the following concept:\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have our candidates, let's run a first experiment. Given the subjective and general nature of the problems dealt by LLMs, its hard to settle on one precise metrics as we would in supervised learning scenarios. \n",
    "\n",
    "Therefore, what we would like to do is to use GPT-4 as the judge for the quality of our models, this approach is actually a common place in prompt engineering papers, and its one that yields some quite impressive results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>response_score</th>\n",
       "      <th>concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain this concept in simple terms</td>\n",
       "      <td>Genetic mutations are changes that happen in t...</td>\n",
       "      <td>I would give this response a score of 90. It p...</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain the following concept:</td>\n",
       "      <td>Genetic mutations are changes or alterations i...</td>\n",
       "      <td>I would give this response a score of 90. It p...</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain this:</td>\n",
       "      <td>Genetic mutations are changes that occur in th...</td>\n",
       "      <td>I would give this response a score of 90. It p...</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Break down this concept for a beginner:</td>\n",
       "      <td>Genetic mutations are changes that occur in ou...</td>\n",
       "      <td>I would give this response a score of 90. It p...</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you simplify the explanation of the follow...</td>\n",
       "      <td>Sure! Genetic mutations are changes that occur...</td>\n",
       "      <td>I would give this response a score of 90. The ...</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0               Explain this concept in simple terms   \n",
       "1                     Explain the following concept:   \n",
       "2                                      Explain this:   \n",
       "3            Break down this concept for a beginner:   \n",
       "4  Can you simplify the explanation of the follow...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Genetic mutations are changes that happen in t...   \n",
       "1  Genetic mutations are changes or alterations i...   \n",
       "2  Genetic mutations are changes that occur in th...   \n",
       "3  Genetic mutations are changes that occur in ou...   \n",
       "4  Sure! Genetic mutations are changes that occur...   \n",
       "\n",
       "                                      response_score  \\\n",
       "0  I would give this response a score of 90. It p...   \n",
       "1  I would give this response a score of 90. It p...   \n",
       "2  I would give this response a score of 90. It p...   \n",
       "3  I would give this response a score of 90. It p...   \n",
       "4  I would give this response a score of 90. The ...   \n",
       "\n",
       "                                           concept  \n",
       "0  Genetic Mutations and Their Impact on Evolution  \n",
       "1  Genetic Mutations and Their Impact on Evolution  \n",
       "2  Genetic Mutations and Their Impact on Evolution  \n",
       "3  Genetic Mutations and Their Impact on Evolution  \n",
       "4  Genetic Mutations and Their Impact on Evolution  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def gpt4_score(response, concept):\n",
    "    score_prompt = f\"Give a score from 0 to 100 to this response: {response} based on how well it represents an explanation of this concept: {concept} \"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an expert tutor in all scientific fields.\"},\n",
    "                  {\"role\": \"user\", \"content\": score_prompt}]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "concept_list = [\"Genetic Mutations and Their Impact on Evolution\", \n",
    "                \"Utilitarianism and Its Influence on Ethics\"]\n",
    "\n",
    "\n",
    "\n",
    "for concept in concept_list:\n",
    "    for prompt in prompt_candidates:\n",
    "        response = get_response(prompt + \" \" + concept)\n",
    "        response_score = gpt4_score(response, concept)\n",
    "        data.append([prompt, response, response_score, concept])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"prompt\", \"response\", \"response_score\", \"concept\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prompt_engineering_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We can see that the score given by the model needs some cleaning up (this is actually an issue that wil be solved by a tool we'll introduce in the next section), so let's do that quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,score_output in enumerate(df[\"response_score\"]):\n",
    "    score_parsed = f\"Given this response, extract the score value and return only that: {score_output}. NUMBER ONLY.\"\n",
    "    score_parsed = get_response(score_parsed)\n",
    "    # replace the response score row with this newly parsed score value\n",
    "    df.loc[i,\"response_score\"] = score_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>response_score</th>\n",
       "      <th>concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain this concept in simple terms</td>\n",
       "      <td>Genetic mutations are changes that happen in t...</td>\n",
       "      <td>90</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain the following concept:</td>\n",
       "      <td>Genetic mutations are changes or alterations i...</td>\n",
       "      <td>90</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain this:</td>\n",
       "      <td>Genetic mutations are changes that occur in th...</td>\n",
       "      <td>90</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Break down this concept for a beginner:</td>\n",
       "      <td>Genetic mutations are changes that occur in ou...</td>\n",
       "      <td>90</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you simplify the explanation of the follow...</td>\n",
       "      <td>Sure! Genetic mutations are changes that occur...</td>\n",
       "      <td>90</td>\n",
       "      <td>Genetic Mutations and Their Impact on Evolution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0               Explain this concept in simple terms   \n",
       "1                     Explain the following concept:   \n",
       "2                                      Explain this:   \n",
       "3            Break down this concept for a beginner:   \n",
       "4  Can you simplify the explanation of the follow...   \n",
       "\n",
       "                                            response response_score  \\\n",
       "0  Genetic mutations are changes that happen in t...             90   \n",
       "1  Genetic mutations are changes or alterations i...             90   \n",
       "2  Genetic mutations are changes that occur in th...             90   \n",
       "3  Genetic mutations are changes that occur in ou...             90   \n",
       "4  Sure! Genetic mutations are changes that occur...             90   \n",
       "\n",
       "                                           concept  \n",
       "0  Genetic Mutations and Their Impact on Evolution  \n",
       "1  Genetic Mutations and Their Impact on Evolution  \n",
       "2  Genetic Mutations and Their Impact on Evolution  \n",
       "3  Genetic Mutations and Their Impact on Evolution  \n",
       "4  Genetic Mutations and Their Impact on Evolution  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results so far:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have some results, now let's take a look at the best performing prompts and compare the answers with the lower performing ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Utilitarianism is a moral and ethical theory that suggests that the right course of action is the one that maximizes overall happiness or utility. It focuses on the consequences of actions rather than the intentions behind them. This theory was developed by philosophers such as Jeremy Bentham and John Stuart Mill.\\n\\nIn utilitarianism, the morality of an action is determined by its usefulness or the amount of happiness it brings to the majority of people. The principle of utility states that actions should be judged based on their ability to create the greatest amount of overall happiness or the least amount of overall suffering.\\n\\nUtilitarianism differs from other ethical theories, such as deontological ethics, which emphasize moral duties and principles, and virtue ethics, which focus on developing noble character traits. Instead, utilitarianism emphasizes the importance of promoting the greatest amount of happiness for the greatest number of people.\\n\\nThe influence of utilitarianism on ethics is significant. It provides a framework for decision-making that is applicable in various fields, including politics, economics, and social justice. Utilitarianism guides policymakers and lawmakers in creating policies and laws that maximize overall well-being. It also plays a role in weighing the benefits and costs associated with different actions, helping individuals and organizations make more ethical choices.\\n\\nCritics argue that utilitarianism can be problematic because it may neglect the rights and welfare of minority groups or individuals. It can also raise questions about how to accurately measure and weigh happiness when making ethical judgments.\\n\\nDespite its drawbacks, utilitarianism has had a significant impact on ethics and has influenced various ethical discussions and debates. Its focus on promoting the overall well-being of society makes it a widely studied and applied ethical theory.',\n",
       "       'Utilitarianism is a consequentialist ethical theory that focuses on maximizing overall happiness or utility for the greatest number of people. It was developed by philosophers like Jeremy Bentham and John Stuart Mill in the 18th and 19th centuries.\\n\\nAccording to utilitarianism, actions are morally right if they produce the greatest amount of happiness or utility for the largest number of people. Conversely, actions are considered morally wrong if they result in unhappiness or reduce overall utility.\\n\\nUtilitarianism places value on the consequences of actions rather than on the intentions behind them. It suggests that the moral worth of an action should be determined by its overall impact on the well-being and happiness of individuals affected by it.\\n\\nUtilitarianism has had a significant influence on ethics and has shaped our moral decision-making in several ways:\\n\\n1. Promoting the Greatest Good: Utilitarianism emphasizes the idea of maximizing overall happiness or utility, making decisions based on what brings the greatest good to the greatest number of people. This concept has influenced various aspects of our lives, including public policy, resource allocation, and healthcare decisions.\\n\\n2. Preference for Evidence-based Decision Making: Utilitarianism encourages decision-making based on empirical evidence rather than personal bias. It encourages gathering data and analyzing the potential outcomes and impacts of different choices before making a decision. This emphasis on evidence-based decision-making has influenced fields such as economics and social sciences.\\n\\n3. Ethical Dilemmas and Trade-offs: Utilitarianism helps us navigate ethical dilemmas and make difficult choices by considering the consequences of our actions. Sometimes, ethical decisions involve trade-offs, where one action may bring happiness to some but cause harm to others. Utilitarianism provides a framework to weigh these trade-offs and make decisions that maximize overall utility.\\n\\n4. Critiques and Modifications: Utilitarianism has also faced critiques and modifications over time. Some argue that it can be too focused on aggregating happiness and overlook individual rights and justice. In response, rule-utilitarianism and preference-utilitarianism have been proposed as modifications to address these concerns and provide a more nuanced approach to ethical decision-making.\\n\\nIn conclusion, utilitarianism has significantly influenced ethics by emphasizing the importance of maximizing overall happiness or utility. It has shaped our understanding of morality, decision-making, and the evaluation of ethical dilemmas, while also generating debates and modifications to address its limitations.',\n",
       "       'Sure, let\\'s break down the concept of Utilitarianism and its influence on ethics for a beginner:\\n\\nUtilitarianism is a moral theory that focuses on the consequences of an action and the amount of overall happiness or pleasure it produces for the greatest number of people. In other words, it judges the morality of an action based on the amount of happiness or utility it brings to the majority.\\n\\nThe central idea of Utilitarianism is known as the \"greatest happiness principle.\" This principle suggests that we should always act in a way that maximizes happiness and minimizes suffering for the greatest number of people.\\n\\nUtilitarianism is an influential theory in ethics because it provides a framework to make moral decisions based on the potential outcomes of our actions. It emphasizes the importance of considering the consequences and the overall well-being of those involved.\\n\\nWhen faced with a moral dilemma, a utilitarian would evaluate the potential consequences of different courses of action and choose the one that would result in the greatest overall happiness. This evaluation includes considering the happiness of all individuals impacted by the decision, not just oneself or a select few.\\n\\nHowever, it\\'s worth noting that Utilitarianism can sometimes raise ethical concerns as well. Because it focuses on the total happiness or utility, individual rights and justice might be compromised in certain situations. For example, if a majority would benefit from the suffering of a minority, Utilitarianism would support that action.\\n\\nOverall, the concept of Utilitarianism is about maximizing overall happiness and minimizing suffering for the greatest number of people, which has a significant influence on ethical decision-making.',\n",
       "       'Utilitarianism is a moral theory that focuses on the overall happiness or well-being of society. It suggests that actions should be evaluated based on the amount of happiness or utility they produce for the greatest number of people.\\n\\nIn ethics, utilitarianism has a significant influence as it encourages people to make decisions or judge the morality of an action by considering the consequences and the good it brings to the majority. This approach prioritizes the collective happiness over individual desires or preferences.\\n\\nIn summary, utilitarianism is a moral theory that emphasizes maximizing overall happiness, and it influences ethics by promoting decisions that benefit the majority.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare lower the responses from the rows with the highest resopnse_score value and the lowest response_score value\n",
    "# to see if there is a difference in the responses\n",
    "\n",
    "df[df['response_score'] == df['response_score'].max()]['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Utilitarianism is a moral theory that focuses on maximizing overall happiness or well-being for the greatest number of people. It suggests that the right action is the one that leads to the greatest amount of happiness for the greatest number of people.\\n\\nIn other words, utilitarianism asks us to consider the consequences of our actions and choose the one that will result in the most overall happiness or well-being. It encourages us to think about how our actions affect others and the greater good.\\n\\nUtilitarianism has a big influence on ethics because it helps us make decisions based on what will bring the most benefit to the most people. It challenges us to think beyond our own desires and consider the well-being of others when making moral choices.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['response_score'] == df['response_score'].min()]['response'].values[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, you would have to tune even the prompt that is being used to create the scores for the responses, to make sure you have the best possible results, but for this particular case let's just analyse overall how well we did with these baseline preliminary results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT](https://ar5iv.labs.arxiv.org/html/2302.11382)\n",
    "- [Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)\n",
    "- [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf)\n",
    "- [prompt engineering guide - zero shot prompting example](https://www.promptingguide.ai/techniques/zeroshot)\n",
    "- [Finetuned language models are zero-shot learners](https://arxiv.org/pdf/2109.01652.pdf)\n",
    "- [prompt engineering guide - few shot prompting](https://www.promptingguide.ai/techniques/fewshot)\n",
    "- [prompt engineering guide - chain of thought prompting](https://www.promptingguide.ai/techniques/cot)\n",
    "- [Wei et al. (2022)](https://arxiv.org/abs/2201.11903)\n",
    "- [prompt engineering guide - self-consistency](https://www.promptingguide.ai/techniques/consistency)\n",
    "- [prompt engineering guide - generate knowledge](https://www.promptingguide.ai/techniques/knowledge)\n",
    "- [Liu et al. 2022](https://arxiv.org/pdf/2110.08387.pdf)\n",
    "- [prompt engineering guide - tree of thoughts (ToT)](https://www.promptingguide.ai/techniques/tot)\n",
    "- [Prompt Engineering by Lilian Weng](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)\n",
    "- [Prompt Engineering vs. Blind Prompting](https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting#the-demonstration-set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly_env",
   "language": "python",
   "name": "oreilly_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
