{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain for LLM App Development \n",
    "\n",
    "We talked about how building an LLM app involves doing some prompt management \n",
    "where we can either prepare the input data from the user with some \n",
    "pre-prompting, or do some post-prompting and some cleaning up after the LLM \n",
    "gives an output to ensure that our app performs the functionalities as expected.\n",
    "\n",
    "So, this kind of workflow usually involves a lot of abstractions where prompts \n",
    "are no longer static pieces of text, but dynamic, they have to integrate \n",
    "information.\n",
    "\n",
    "![](./images/Notebook_4-dynamic_prompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dynamics requirement from a prompt will lead to the need for creating certain types of abstractions to properly handle and manage prompts effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another need in the context of more complex LLM App development, is the need for chaining prompts together, meaning connecting the output of one prompt to another. This is often the case for when prompts might be too large and a single call to the LLM won't be enough to solve the problem or the context window (maximum tokens/words the model can read and writer per request) is exceeded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/Notebook_4-prompt_chaining.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanchain\n",
    "\n",
    "[Langchain](https://python.langchain.com/docs/get_started/introduction.html) is a framework created by Harrison Chase that facilitates the creation and management of dynamic prompts and chaining between prompts.\n",
    "\n",
    "Its main features are:\n",
    "- **Components**: abstractions for working with LMs\n",
    "- **Off-the-shelf chains**: assembly of components for accomplishing certain higher-level tasks\n",
    "\n",
    "With langchain it becomes much easier to create what are called Prompt Templates, which are prompts that can take in user data and abstract away the need for typing out everything that is required for a task to get done.\n",
    "\n",
    "Let's take a look at some simple examples to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create an application with LangChain, we need to understand its core components:\n",
    "\n",
    "- Models\n",
    "- Prompts\n",
    "- Indexes\n",
    "- Chains\n",
    "- Agents (won't go into it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-08-17-14-48-39.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "abstractions over the LLM APIs like the ChatGPT API.â€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can predict outputs from both LLMs and ChatModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict(\"hi!\")\n",
    "# Output: \"Hi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the predict method over a string input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Snuggles'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good name for a dog that loves to nap??\"\n",
    "\n",
    "\n",
    "chat_model.predict(text)\n",
    "# Output: \"Snuggles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the `predict_messages` method over a list of messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A good dog name for a dog that loves to nap could be \"Snooze\" or \"Snuggles\".', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good dog name for a dog that loves to nap?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "chat_model.predict_messages(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "Prompt Templates are useful abstractions for reusing prompts. \n",
    "\n",
    "They are used to provide context for the specific task that the language model needs to complete. \n",
    "A simple example is a `PromptTemplate` that formats a string into a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good dog name for a dog that loves to nap?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good dog name for a dog that loves to {activity}?\")\n",
    "prompt.format(activity=\"nap\")\n",
    "# Output: \"What is a good dog name for a dog that loves to nap?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Biscuit'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt,\n",
    ")\n",
    "chain.run(\"eat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create more complex ChatPromptTemplates that contains a list of ChatMessageTemplates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Parsers**\n",
    "\n",
    "OutputParsers convert the raw output from an LLM into a format that can be used downstream. Here is an example of an OutputParser that converts a comma-separated list into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")\n",
    "# Output: ['hi', 'bye']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLMChain**\n",
    "\n",
    "Finally, you can combine all these components into an LLMChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Golden Retriever',\n",
       " 'Labrador Retriever',\n",
       " 'German Shepherd',\n",
       " 'Bulldog',\n",
       " 'Beagle']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generated 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"dogs\")\n",
    "# Output: ['Golden Retriever','Labrador Retriever','German Shepherd','Bulldog','Poodle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to an LLM, and then pass the output through an output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so these are the basics of langchain. But how can we leverage these abstraction capabilities inside our LLM app application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the best applications of langchain is for the \"chat with your data\"-types of applications, where the user uploads a document like a pdf or a .txt file, and is able to query that document using langchain powered by an LLM like ChatGPT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Lab Exercises\n",
    "\n",
    "Let's take a look at a simple example of **Simple Sequential Chain**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = ChatOpenAI(temperature=.7)\n",
    "template = \"\"\"You are a learning assistant. Given a technical subject, write down 5 fundamental concepts to understand it.\n",
    "Subject: {subject}\n",
    "Learning assistant: The 5 fundamental concepts are:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"subject\"], template=template)\n",
    "learning_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = ChatOpenAI(temperature=.7)\n",
    "template = \"\"\"You are an expert teacher in all technical and scientific fields. Given a list of 5 concepts, write down a simple intuitive explanation of each concept.\n",
    "Concepts:\n",
    "{concepts}\n",
    "Intuitive explanations:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"concepts\"], template=template)\n",
    "explanation_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "learning_overall_chain = SimpleSequentialChain(chains=[learning_chain, explanation_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. Additive Manufacturing: 3D printing is a form of additive manufacturing, where objects are created by adding layers of material on top of each other. Understanding the process of additive manufacturing is essential to grasp the fundamentals of 3D printing.\n",
      "\n",
      "2. CAD Modeling: Computer-Aided Design (CAD) is a crucial aspect of 3D printing. Learning how to create digital 3D models using CAD software allows users to design and customize objects before printing them. Understanding the basics of CAD modeling is necessary to utilize 3D printers effectively.\n",
      "\n",
      "3. Slicing: Slicing is the process of dividing a 3D model into multiple layers or slices. Each layer is then printed individually to create the final object. Understanding how slicing works, including parameters such as layer height and print speed, is essential for optimal 3D printing results.\n",
      "\n",
      "4. Materials and Filaments: Different materials and filaments can be used in 3D printing, each with its own properties and applications. Understanding the characteristics, limitations, and compatibility of various materials is crucial in selecting the appropriate filament for specific 3D printing projects.\n",
      "\n",
      "5. Post-Processing: 3D printed objects often require post-processing to improve their appearance, strength, or functionality. Learning about post-processing techniques such as sanding, painting, polishing, or assembling is essential to achieve the desired final result.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. Additive Manufacturing: Additive manufacturing is like building a house with Legos. Instead of carving a solid object from a block of material, we stack thin layers on top of each other until we create the desired shape. It's like adding one Lego piece at a time to create something unique and custom-made.\n",
      "\n",
      "2. CAD Modeling: CAD modeling is like designing a virtual object on a computer. It's like using a digital sculpting tool to shape and mold a 3D model, just like an artist would shape clay with their hands. With CAD modeling, we can create precise and detailed designs before bringing them to life with a 3D printer.\n",
      "\n",
      "3. Slicing: Slicing is like cutting a cake into multiple layers. Just like we cut a cake into slices, we divide a 3D model into many thin layers. Each layer represents a slice that will be printed individually. Think of it as creating a stack of transparent sheets, where each sheet represents a different layer of the object.\n",
      "\n",
      "4. Materials and Filaments: Materials and filaments in 3D printing are like different types of ingredients in cooking. Just as we choose specific ingredients for different recipes, we select specific materials and filaments based on their properties and applications. Some materials may be strong and durable, while others may be flexible or heat-resistant.\n",
      "\n",
      "5. Post-Processing: Post-processing is like adding finishing touches to a painting. After we print a 3D object, it may not look or feel exactly how we want it to. Post-processing techniques, such as sanding, painting, or assembling, allow us to refine and enhance the printed object. It's like adding colors, textures, and extra details to make it look even better.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"1. Additive Manufacturing: Additive manufacturing is like building a house with Legos. Instead of carving a solid object from a block of material, we stack thin layers on top of each other until we create the desired shape. It's like adding one Lego piece at a time to create something unique and custom-made.\\n\\n2. CAD Modeling: CAD modeling is like designing a virtual object on a computer. It's like using a digital sculpting tool to shape and mold a 3D model, just like an artist would shape clay with their hands. With CAD modeling, we can create precise and detailed designs before bringing them to life with a 3D printer.\\n\\n3. Slicing: Slicing is like cutting a cake into multiple layers. Just like we cut a cake into slices, we divide a 3D model into many thin layers. Each layer represents a slice that will be printed individually. Think of it as creating a stack of transparent sheets, where each sheet represents a different layer of the object.\\n\\n4. Materials and Filaments: Materials and filaments in 3D printing are like different types of ingredients in cooking. Just as we choose specific ingredients for different recipes, we select specific materials and filaments based on their properties and applications. Some materials may be strong and durable, while others may be flexible or heat-resistant.\\n\\n5. Post-Processing: Post-processing is like adding finishing touches to a painting. After we print a 3D object, it may not look or feel exactly how we want it to. Post-processing techniques, such as sanding, painting, or assembling, allow us to refine and enhance the printed object. It's like adding colors, textures, and extra details to make it look even better.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = learning_overall_chain.run(\"3D printing\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = ChatOpenAI(temperature=.7)\n",
    "template = \"\"\"You are a learning assistant. Given a technical subject, write down 5 fundamental concepts to understand it.\n",
    "Subject: {subject}\n",
    "Field: {field}\n",
    "Learning assistant: The 5 fundamental concepts are:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"subject\", \"field\"], template=template)\n",
    "learning_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = ChatOpenAI(temperature=.7)\n",
    "template = \"\"\"You are an expert teacher in all technical and scientific fields. Given a list of 5 concepts, write down a simple intuitive explanation of each concept.\n",
    "\n",
    "Concepts:\n",
    "{concepts}\n",
    "Intuitive explanations:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"concepts\"], template=template)\n",
    "explanation_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"explanations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "learning_overall_chain = SequentialChain(\n",
    "    chains=[learning_chain, explanation_chain],\n",
    "    input_variables=[\"subject\", \"field\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"concepts\", \"explanations\"],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subject': '3D Printing',\n",
       " 'field': 'engineering',\n",
       " 'concepts': '1. Additive Manufacturing: 3D printing is a type of additive manufacturing, which means it creates objects by adding layers of material on top of each other. Understanding this concept is crucial to comprehend the basic principle behind 3D printing technology.\\n\\n2. CAD Design: Computer-Aided Design (CAD) is an essential component of 3D printing. CAD software allows engineers to create digital models of objects that can then be printed in 3D. Understanding how to design and manipulate objects using CAD software is fundamental to the 3D printing process.\\n\\n3. Materials and Filaments: Different materials can be used for 3D printing, such as plastics, metals, ceramics, and even biological materials. Understanding the characteristics and properties of these materials and filaments is important to choose the appropriate material for a specific 3D printing project.\\n\\n4. Printing Technologies: There are various 3D printing technologies available, including Fused Deposition Modeling (FDM), Stereolithography (SLA), Selective Laser Sintering (SLS), and more. Each technology has its own advantages, limitations, and applications. Understanding the different printing technologies helps in selecting the most suitable method for a given project.\\n\\n5. Post-Processing and Finishing: 3D printed objects may require post-processing and finishing to improve their appearance, strength, or functionality. This can involve processes like sanding, polishing, painting, or even additional assembly. Understanding the post-processing techniques and finishing methods is crucial to achieving the desired final product in 3D printing.',\n",
       " 'explanations': \"1. Additive Manufacturing: Imagine building a house with Legos. Additive manufacturing is like putting one Lego block on top of another to create the whole house. 3D printing works the same way, adding layer upon layer of material to build an object from scratch.\\n\\n2. CAD Design: CAD design is like using a virtual sculpting tool to create a digital model of an object. It's like molding clay, but on a computer screen. Engineers can shape and manipulate the object in the digital world before bringing it to life through 3D printing.\\n\\n3. Materials and Filaments: Just like choosing the right ingredients for a recipe, selecting the appropriate material for 3D printing is crucial. Different materials have different properties, just like how flour, sugar, and butter have different effects on baking. Understanding these characteristics helps in picking the best material for each printing project.\\n\\n4. Printing Technologies: Think of printing technologies as different types of printers. Each printer has its own way of creating the object. It's like choosing between a regular inkjet printer or a laser printer for different printing needs. Understanding the different technologies helps in picking the most suitable printer for the job.\\n\\n5. Post-Processing and Finishing: Imagine creating a sculpture out of clay. After shaping it, you might smooth out rough edges, paint it, or add some final touches to make it look perfect. Similarly, 3D printed objects often need some extra steps like sanding, painting, or assembly to make them look and function as intended. Understanding these finishing techniques is like putting the final polish on a masterpiece.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_overall_chain({\"subject\":\"3D Printing\", \"field\": \"engineering\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Q&A Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docarray\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Superhero Name</th>\n",
       "      <th>Superpower</th>\n",
       "      <th>Power Level</th>\n",
       "      <th>Catchphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Captain Thunder</td>\n",
       "      <td>Bolt Manipulation</td>\n",
       "      <td>90</td>\n",
       "      <td>Feel the power of the storm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Falcon</td>\n",
       "      <td>Flight and Agility</td>\n",
       "      <td>85</td>\n",
       "      <td>Soar high, fearlessly!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mystic Shadow</td>\n",
       "      <td>Invisibility and Illusions</td>\n",
       "      <td>78</td>\n",
       "      <td>Disappear into the darkness!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blaze Runner</td>\n",
       "      <td>Pyrokinesis</td>\n",
       "      <td>88</td>\n",
       "      <td>Burn bright and fierce!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electra-Wave</td>\n",
       "      <td>Electric Manipulation</td>\n",
       "      <td>82</td>\n",
       "      <td>Unleash the electric waves!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Superhero Name                  Superpower  Power Level  \\\n",
       "0  Captain Thunder           Bolt Manipulation           90   \n",
       "1    Silver Falcon          Flight and Agility           85   \n",
       "2    Mystic Shadow  Invisibility and Illusions           78   \n",
       "3     Blaze Runner                 Pyrokinesis           88   \n",
       "4     Electra-Wave       Electric Manipulation           82   \n",
       "\n",
       "                    Catchphrase  \n",
       "0  Feel the power of the storm!  \n",
       "1        Soar high, fearlessly!  \n",
       "2  Disappear into the darkness!  \n",
       "3       Burn bright and fierce!  \n",
       "4   Unleash the electric waves!  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./superheroes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'superheroes.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's set up our Vector store (we'll talk about what that is in a second):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me the catch phrase for Captain Thunder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Captain Thunder's catchphrase is \"Feel the power of the storm!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, cool! So, now let's backtrack a little bit and discuss what is going on.\n",
    "\n",
    "If we want LLMs to get access to our data in order to help us get insights, we have one major problem: LLMs have a limited context window, meaning they can only process a few thousand words at a time which constraints their ability to answer questions (for example) of really big documents. \n",
    "\n",
    "That's where things like embeddings and vector stores come into play, these are way of representing the data in such a way to facilitate the access by an LLM. Let's break it down, starting with embeddings:\n",
    "\n",
    "Embeddings are numerical representations of data, meaning, their a way to represent data such that the semantic information of that data is properly reflected in the distances between the data points in the embedding.\n",
    "\n",
    "That means that text with similar content will have similar vectors (which is a way of saying that they'll be closer together in the embedding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-07-30-19-29-27.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's talk about vector databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector database is a way to store these embeddings, these numerical representations that we just discussed.\n",
    "\n",
    "The pipeline is:\n",
    "- In coming document\n",
    "- Create chunks of text from that document\n",
    "- Embed each chunk\n",
    "- Store these embeddings\n",
    "\n",
    "![](2023-07-30-19-32-13.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can query those embeddings stored in the vector database to get the most relevant responses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we create a query, that query is first embedded and then we compare its embedding with the embeddings we have stored in the vector database. We then select the N-most similar embeddings, and pass those to the LLM.\n",
    "\n",
    "![](images/2023-07-30-19-34-48.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Embedding__: the useful data representation that will be used as the thing (or things) we can query\n",
    "- __Vector Database__: the vectorization of the embedding chunks (the database for the embeddings where we can do the query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "\n",
    "![](./images/embeddings.png)\n",
    "\n",
    "![](./images/embeddings2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](./images/2023-07-17-12-48-28.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://python.langchain.com/docs/get_started/introduction.html\n",
    "- https://medium.com/@remitoffoli/a-visual-guide-to-llm-powered-app-architecture-57e47426a92f\n",
    "- [LangChain for LLM App Development short course by coursera](https://learn.deeplearning.ai/langchain/lesson/5/question-and-answer)\n",
    "- [LLM Evaluation](https://learn.deeplearning.ai/langchain/lesson/6/evaluation)\n",
    "[Models, Prompts, parsers, memory and chains from this langchain for](https://learn.deeplearning.ai/langchain/lesson/7/agents)\n",
    "- [Chat With Your Data - Retrieval](https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/5/retrieval)\n",
    "- [Emebeddings simple definition](https://learn.deeplearning.ai/langchain/lesson/5/question-and-answer)\n",
    "- [Vector DBs - simple definition](https://learn.deeplearning.ai/langchain/lesson/5/question-and-answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly_env",
   "language": "python",
   "name": "oreilly_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
