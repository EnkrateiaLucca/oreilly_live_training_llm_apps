{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# loading from a .env file\n",
    "# load_dotenv(dotenv_path=\"/full/path/to/your/.env\")\n",
    "\n",
    "# or \n",
    "# if you're on google colab just uncomment below and replace with your openai api key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your-openai-api-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to ChatGPT API\n",
    "\n",
    "- Where does ChatGPT fit into this chaotic universe?\n",
    "- The ChatGPT API (what’s the deal?)\n",
    "- How to use it, basics, parameters, simple examples, etc…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request body for the CHATGPT API involves many parameters, but let's focus on the following:\n",
    "\n",
    "- model: ID of the model to use.\n",
    "- messages: a list of messages comprising the conversation up to that point\n",
    "- temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "- n: number of chat completion choices to generate for each input message\n",
    "- max_tokens: the maximum number of tokens to generate in the chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A3P3n9PdiedVMjUnFvDKuD4kEgxpt', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='The meaning of life is a question that has puzzled humanity for centuries, and it often depends on individual beliefs and perspectives. Here are a few different interpretations:\\n\\n1. **Philosophical Perspective**: Many philosophers argue that life’s meaning is subjective. Each person creates their own meaning through experiences, relationships, and personal growth. Existentialists, for example, believe that individuals must find their own purpose in a seemingly indifferent universe.\\n\\n2. **Spiritual Perspective**: Many spiritual traditions suggest that', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725374679, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_f33667828e', usage=CompletionUsage(completion_tokens=100, prompt_tokens=34, total_tokens=134))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "prompt = \"What is the meaning of life?\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "                             model=\"gpt-4o-mini\",\n",
    "                             messages=\n",
    "                             [\n",
    "                                 {\"role\": \"system\", \"content\": \"You are a savy guru with knowledge about existence and the secrets of life.\"},\n",
    "                                 {\"role\": \"user\", \"content\": prompt}   \n",
    "                             ],\n",
    "                             max_tokens=100, # the maximum number of tokens to generate\n",
    "                             temperature=0.9, # the level of randomness in the generated text, so close to 0 means super precise, close to 2 means more creative\n",
    "                             n = 1)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: chatcmpl-A3P3n9PdiedVMjUnFvDKuD4kEgxpt\n",
      "Choices: [Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='The meaning of life is a question that has puzzled humanity for centuries, and it often depends on individual beliefs and perspectives. Here are a few different interpretations:\\n\\n1. **Philosophical Perspective**: Many philosophers argue that life’s meaning is subjective. Each person creates their own meaning through experiences, relationships, and personal growth. Existentialists, for example, believe that individuals must find their own purpose in a seemingly indifferent universe.\\n\\n2. **Spiritual Perspective**: Many spiritual traditions suggest that', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
      "Created: 1725374679\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "System Fingerprint: fp_f33667828e\n",
      "Object Type: chat.completion\n",
      "Usage: CompletionUsage(completion_tokens=100, prompt_tokens=34, total_tokens=134)\n"
     ]
    }
   ],
   "source": [
    "print(\"Response ID:\", response.id)\n",
    "print(\"Choices:\", response.choices)\n",
    "print(\"Created:\", response.created)\n",
    "print(\"Model:\", response.model)\n",
    "print(\"System Fingerprint:\", response.system_fingerprint)\n",
    "print(\"Object Type:\", response.object)\n",
    "print(\"Usage:\", response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://platform.openai.com/docs/api-reference/chat/object\n",
    "\n",
    "### Chat Completion Object\n",
    "This object represents a chat completion response returned by the model, based on the provided input.\n",
    "\n",
    "#### Fields\n",
    "\n",
    "- **id**  \n",
    "  `string`  \n",
    "  A unique identifier for the chat completion.\n",
    "\n",
    "- **choices**  \n",
    "  `array`  \n",
    "  A list of chat completion choices. Can be more than one if `n` is greater than 1.\n",
    "\n",
    "#### Additional Properties\n",
    "\n",
    "- **created**  \n",
    "  `integer`  \n",
    "  The Unix timestamp (in seconds) of when the chat completion was created.\n",
    "\n",
    "- **model**  \n",
    "  `string`  \n",
    "  The model used for the chat completion.\n",
    "\n",
    "- **system_fingerprint**  \n",
    "  `string`  \n",
    "  This fingerprint represents the backend configuration that the model runs with. It can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.\n",
    "\n",
    "- **object**  \n",
    "  `string`  \n",
    "  The object type, which is always `chat.completion`.\n",
    "\n",
    "- **usage**  \n",
    "  `object`  \n",
    "  Usage statistics for the completion request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bamboo crunching sound,  \n",
      "Lazy bears in black and white,  \n",
      "Life's a bamboo feast!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_response(prompt, system_message=\"You are a savy guru with knowledge about existence and the secrets of life.\"):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(model=\"gpt-4o-mini\", \n",
    "                             messages=\n",
    "                             [\n",
    "                                 {\"role\": \"system\", \"content\": system_message},\n",
    "                                 {\"role\": \"user\", \"content\": prompt}   \n",
    "                             ],\n",
    "                             max_tokens=100, # max number of tokens in a response\n",
    "                             temperature=0.9, # level of randomness in the response\n",
    "                             n = 1) # number of responses we expect from the model\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "prompt = \"Tell me a joke as a haiku about Pandas\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my name is Lucas Soares and I like to give courses on language models.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt=\"You are translation engine for any language.\\\n",
    "    The user will feed you with some text and the target language \\\n",
    "        in between brackets: like this: '[english]' \\\n",
    "            and you will output only the translation.\" \n",
    "\n",
    "def translate(prompt, system_message):\n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
    "                                messages=\n",
    "                                [\n",
    "                                    {\"role\": \"system\", \"content\": system_message},\n",
    "                                    {\"role\": \"user\", \"content\": prompt}   \n",
    "                                ],\n",
    "                                max_tokens=100,\n",
    "                                temperature=0.9,\n",
    "                                n = 1)\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "translate(\"Ola meu nome e Lucas Soares e eu gosto de dar cursos sobre models de linguage.\",system_message_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Basics\n",
    "\n",
    "A prompt is a piece of text that conveys to a LLM what the user wants. What the user wants can be many things like:\n",
    "\n",
    "- Asking a question\n",
    "- Giving an instruction\n",
    "- Etc...\n",
    "\n",
    "The key components of a prompt are:\n",
    "1. Instruction: where you describe what you want\n",
    "2. Context: additional information to help with performance\n",
    "3. Input data: data the model has not seem to illustrate what you need\n",
    "4. Output indicator: How you prime the model to output what you want, for example asking the model [\"Let's think step by step\" and the end of a prompt can boost reasoning performance](https://arxiv.org/pdf/2201.11903.pdf). You can also write \"Output:\" to prime the model to just write the output and nothing else.\n",
    "\n",
    "[Prompts can also be seen as a form of programming that can customize the outputs and interactions with an LLM.](https://ar5iv.labs.arxiv.org/html/2302.11382#:~:text=prompts%20are%20also%20a%20form%20of%20programming%20that%20can%20customize%20the%20outputs%20and%20interactions%20with%20an%20llm.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Classify this sentence into positive or negative:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Data & Context Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"Text: I like eating pancakes.\"\n",
    "\n",
    "context = \"You are a text annotation engine.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indicator = \"Output:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How you ask what you want, and the heavily relies on what you want from the model.\n",
    "# Instruction prompt: \n",
    "\n",
    "instruction_prompt = f\"{context}.\\n{instruction}.\\n{input_data}. {output_indicator}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a text annotation engine..\\nClassify this sentence into positive or negative:.\\nText: I like eating pancakes.. Output:\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output: Positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and programming assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "get_response(instruction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indicator = \"The output should ONLY be either the word 'positive' or 'negative' and nothing else. Output:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = f\"{context}.\\n{instruction}.\\n{input_data}. {output_indicator}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(instruction_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first super simple prompt engineering experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICE ROUND\n",
    "# WRITE A SIMPLE PROMPT OUTLINING EACH COMPONENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = \"\"\n",
    "context = \"\"\n",
    "input_data = \"\"\n",
    "output_indicator = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AF!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, broccoli is a very healthy food choice. It is low in calories but high in nutrients like vitamins C and K, fiber, and antioxidants. It can be a great addition to a healthy diet.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"You are a healthy diet assistant you answer questions about food\"\n",
    "instruction = \"Is healthy to eat the following food?\" \n",
    "input_data = \"[food]: brocoli\"\n",
    "output_indicator = \"[answer]: \"\n",
    "\n",
    "instruction_prompt = f\"{context}.\\n{instruction}.\\n{input_data}. {output_indicator}\"\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": instruction_prompt}\n",
    "])\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, # describes overall behavior\n",
    "            {\"role\": \"user\", \"content\": prompt} #message from the user\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "prompt = \"Tell me a joke\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT](https://ar5iv.labs.arxiv.org/html/2302.11382)\n",
    "- [Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)\n",
    "- [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf)\n",
    "- [prompt engineering guide - zero shot prompting example](https://www.promptingguide.ai/techniques/zeroshot)\n",
    "- [Finetuned language models are zero-shot learners](https://arxiv.org/pdf/2109.01652.pdf)\n",
    "- [prompt engineering guide - few shot prompting](https://www.promptingguide.ai/techniques/fewshot)\n",
    "- [prompt engineering guide - chain of thought prompting](https://www.promptingguide.ai/techniques/cot)\n",
    "- [Wei et al. (2022)](https://arxiv.org/abs/2201.11903)\n",
    "- [prompt engineering guide - self-consistency](https://www.promptingguide.ai/techniques/consistency)\n",
    "- [prompt engineering guide - generate knowledge](https://www.promptingguide.ai/techniques/knowledge)\n",
    "- [Liu et al. 2022](https://arxiv.org/pdf/2110.08387.pdf)\n",
    "- [prompt engineering guide - tree of thoughts (ToT)](https://www.promptingguide.ai/techniques/tot)\n",
    "- [Prompt Engineering by Lilian Weng](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)\n",
    "- [Prompt Engineering vs. Blind Prompting](https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting#the-demonstration-set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-chatgpt-apps",
   "language": "python",
   "name": "oreilly-chatgpt-apps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
