{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Trying Out Different Learning Acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADEPT\n",
    "\n",
    "- A:= analogy\n",
    "- D:= diagram\n",
    "- E:= example\n",
    "- P:= plain english\n",
    "- T:= technical definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This still needs a bridge into what the person cares about. So teachiing some formalization technique or trick to bring that person's interests into the problem/concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Set OPENAI API Key\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your openai key\"\n",
    "\n",
    "# OR (load from .env file)\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analogy': AIMessage(content='A joint probability mass function is like a recipe that tells you the chances of two ingredients coming together in a dish, determining the overall probability of a successful outcome.'),\n",
       " 'diagram': AIMessage(content='**Concept: Joint Probability Mass Function**\\n\\n- **Definition**: A joint probability mass function (PMF) is a function that gives the probability that two discrete random variables X and Y take on specific values x and y simultaneously.\\n\\n- **Related Concepts**:\\n  - **Probability Mass Function (PMF)**: A function that gives the probability that a discrete random variable takes on a specific value.\\n  - **Random Variables**: Variables that can take on different values based on the outcome of a random event.\\n  - **Marginal Probability**: The probability of an event occurring for a single random variable in a joint distribution.\\n  - **Conditional Probability**: The probability of an event occurring given that another event has already occurred.\\n\\n- **Uses**:\\n  - Joint PMFs are used to model the relationship between two or more random variables and can be used to calculate various probabilities and make predictions.\\n\\n- **Formula**:\\n  - P(X=x, Y=y) = P(X=x ∩ Y=y)\\n\\n- **Example**:\\n  - If X represents the number of heads when flipping two coins and Y represents the number of tails, the joint PMF would give the probabilities of getting 0, 1, or 2 heads and tails.\\n\\n- **Notation**:\\n  - P(X=x, Y=y) or P(X,Y)(x,y)\\n\\n- **Properties**:\\n  - Joint PMFs must satisfy the properties of probability, i.e., they must be non-negative and sum to 1 over all possible values of X and Y.\\n\\n- **Applications**:\\n  - Used in fields such as statistics, machine learning, and decision theory to model and analyze the relationships between multiple random variables.'),\n",
       " 'example': AIMessage(content='1. Rolling a fair six-sided die twice and calculating the probability of getting a 1 on the first roll and a 2 on the second roll.\\n2. Choosing a card from a standard deck of 52 cards twice and calculating the probability of drawing a red card followed by a face card.\\n3. Flipping a fair coin three times and calculating the probability of getting heads on the first two flips and tails on the third flip.\\n4. Selecting two marbles from a bag containing 3 red marbles and 2 blue marbles without replacement, and calculating the probability of selecting a red marble followed by a blue marble.\\n5. Choosing two numbers at random from the set {1, 2, 3, 4, 5} and calculating the probability of selecting 1 and then selecting an odd number.'),\n",
       " 'plain_english': AIMessage(content='A joint probability mass function is a mathematical function that shows the likelihood of two or more random variables occurring together in a set of data.'),\n",
       " 'technical_def': AIMessage(content='A joint probability mass function is a mathematical function that assigns probabilities to combinations of values for multiple random variables in a discrete probability distribution.')}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def chain_analogy(llm): \n",
    "    return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "        what it is.\") | llm\n",
    "\n",
    "def chain_diagram(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "        what it is and what it relates to.\") | llm\n",
    "\n",
    "def chain_example(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm\n",
    "\n",
    "\n",
    "def chain_plain_english(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "def chain_technical_definition(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "llm_chat = ChatOpenAI()\n",
    "\n",
    "analogy_chain = chain_analogy(llm_chat)\n",
    "diagram_chain = chain_diagram(llm_chat)\n",
    "example_chain = chain_example(llm_chat)\n",
    "plain_english_chain = chain_plain_english(llm_chat)\n",
    "technical_definition_chain = chain_technical_definition(llm_chat)\n",
    "\n",
    "\n",
    "concept = \"joint probability mass function\"\n",
    "map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "output_explanation = map_chain.invoke({\"concept\": concept})\n",
    "output_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**analogy**\n",
       "\n",
       "A joint probability mass function is like a recipe that tells you the chances of two ingredients coming together in a dish, determining the overall probability of a successful outcome.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**diagram**\n",
       "\n",
       "**Concept: Joint Probability Mass Function**\n",
       "\n",
       "- **Definition**: A joint probability mass function (PMF) is a function that gives the probability that two discrete random variables X and Y take on specific values x and y simultaneously.\n",
       "\n",
       "- **Related Concepts**:\n",
       "  - **Probability Mass Function (PMF)**: A function that gives the probability that a discrete random variable takes on a specific value.\n",
       "  - **Random Variables**: Variables that can take on different values based on the outcome of a random event.\n",
       "  - **Marginal Probability**: The probability of an event occurring for a single random variable in a joint distribution.\n",
       "  - **Conditional Probability**: The probability of an event occurring given that another event has already occurred.\n",
       "\n",
       "- **Uses**:\n",
       "  - Joint PMFs are used to model the relationship between two or more random variables and can be used to calculate various probabilities and make predictions.\n",
       "\n",
       "- **Formula**:\n",
       "  - P(X=x, Y=y) = P(X=x ∩ Y=y)\n",
       "\n",
       "- **Example**:\n",
       "  - If X represents the number of heads when flipping two coins and Y represents the number of tails, the joint PMF would give the probabilities of getting 0, 1, or 2 heads and tails.\n",
       "\n",
       "- **Notation**:\n",
       "  - P(X=x, Y=y) or P(X,Y)(x,y)\n",
       "\n",
       "- **Properties**:\n",
       "  - Joint PMFs must satisfy the properties of probability, i.e., they must be non-negative and sum to 1 over all possible values of X and Y.\n",
       "\n",
       "- **Applications**:\n",
       "  - Used in fields such as statistics, machine learning, and decision theory to model and analyze the relationships between multiple random variables.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**example**\n",
       "\n",
       "1. Rolling a fair six-sided die twice and calculating the probability of getting a 1 on the first roll and a 2 on the second roll.\n",
       "2. Choosing a card from a standard deck of 52 cards twice and calculating the probability of drawing a red card followed by a face card.\n",
       "3. Flipping a fair coin three times and calculating the probability of getting heads on the first two flips and tails on the third flip.\n",
       "4. Selecting two marbles from a bag containing 3 red marbles and 2 blue marbles without replacement, and calculating the probability of selecting a red marble followed by a blue marble.\n",
       "5. Choosing two numbers at random from the set {1, 2, 3, 4, 5} and calculating the probability of selecting 1 and then selecting an odd number.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**plain_english**\n",
       "\n",
       "A joint probability mass function is a mathematical function that shows the likelihood of two or more random variables occurring together in a set of data.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**technical_def**\n",
       "\n",
       "A joint probability mass function is a mathematical function that assigns probabilities to combinations of values for multiple random variables in a discrete probability distribution.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "for key in output_explanation.keys():\n",
    "    display(Markdown(f\"**{key}**\\n\\n{output_explanation[key].content}\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is nice but can we make it better? Like the knowledge graph is not visual, how can we improve upon that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from graphviz import Digraph\n",
    "import argparse\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "class Node(BaseModel):\n",
    "    id: int\n",
    "    label: str\n",
    "    color: str\n",
    "\n",
    "class Edge(BaseModel):\n",
    "    source: int\n",
    "    target: int\n",
    "    label: str\n",
    "    color: str = \"black\"\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"A knowledge graph is a graph that represents knowledge as a set of entities and relations between them.\"\"\"\n",
    "    nodes: List[Node] = Field(..., description=\"A list of nodes in the knowledge graph\")\n",
    "    edges: List[Edge] = Field(..., description=\"A list of edges in the knowledge graph\")\n",
    "\n",
    "\n",
    "def visualize_knowledge_graph(kg: KnowledgeGraph):\n",
    "    dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "    # Add nodes\n",
    "    for node in kg.nodes:\n",
    "        dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "    # Add edges\n",
    "    for edge in kg.edges:\n",
    "        dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "    # Render the graph\n",
    "    display(graphviz.Source(dot.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's modify the `chain_diagram()` function to output a schema that's appropriate for generating a knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"nodes\":[{\"id\":1,\"label\":\"Large Language Models\",\"color\":\"#FF5733\"},{\"id\":2,\"label\":\"Artificial Intelligence\",\"color\":\"#FFC300\"},{\"id\":3,\"label\":\"Natural Language Processing\",\"color\":\"#C70039\"}],\"edges\":[{\"source\":1,\"target\":2,\"label\":\"is a type of\"},{\"source\":1,\"target\":3,\"label\":\"applies to\"}]}', 'name': 'KnowledgeGraph'}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n",
    "\n",
    "llm_chat = ChatOpenAI()    \n",
    "llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "\n",
    "chain = chain_diagram(llm_with_tools)\n",
    "concept = \"large language models\"\n",
    "\n",
    "output_graph = chain.invoke({\"concept\": concept})\n",
    "output_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we are getting the right output, which we can access like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"nodes\":[{\"id\":1,\"label\":\"Large Language Models\",\"color\":\"#FF5733\"},{\"id\":2,\"label\":\"Artificial Intelligence\",\"color\":\"#FFC300\"},{\"id\":3,\"label\":\"Natural Language Processing\",\"color\":\"#C70039\"}],\"edges\":[{\"source\":1,\"target\":2,\"label\":\"is a type of\"},{\"source\":1,\"target\":3,\"label\":\"applies to\"}]}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.additional_kwargs[\"function_call\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want this output to be perfectly tailored for a function that visualizes the graph, so let's do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"nodes\":[{\"id\":1,\"label\":\"Large Language Models\",\"color\":\"#FF5733\"},{\"id\":2,\"label\":\"Artificial Intelligence\",\"color\":\"#FFC300\"},{\"id\":3,\"label\":\"Natural Language Processing\",\"color\":\"#C70039\"}],\"edges\":[{\"source\":1,\"target\":2,\"label\":\"is a type of\"},{\"source\":1,\"target\":3,\"label\":\"applies to\"}]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "\n",
    "output_graph_json_dict = output_graph.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "output_graph_json_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes=[Node(id=1, label='Large Language Models', color='#FF5733'), Node(id=2, label='Artificial Intelligence', color='#FFC300'), Node(id=3, label='Natural Language Processing', color='#C70039')], edges=[Edge(source=1, target=2, label='is a type of', color='black'), Edge(source=1, target=3, label='applies to', color='black')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydantic_output_parser.parse(output_graph_json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! As you can see above, the output of parsing with the pydantic_output_parser is the `KnowledgeGraph` object, which we can feed into the \n",
    "`visualize_graph` function to get the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"448pt\" height=\"133pt\"\n",
       " viewBox=\"0.00 0.00 447.69 132.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 128.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-128.5 443.69,-128.5 443.69,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff5733\" cx=\"204.76\" cy=\"-106.5\" rx=\"102.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"204.76\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Large Language Models</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffc300\" cx=\"90.76\" cy=\"-18\" rx=\"90.76\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"90.76\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Artificial Intelligence</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.51,-88.62C165.25,-75.52 141.11,-57.2 121.92,-42.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.24,-40.01 114.16,-36.76 120.01,-45.59 124.24,-40.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"189.14\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">is a type of</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#c70039\" cx=\"319.76\" cy=\"-18\" rx=\"119.93\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.76\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Natural Language Processing</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.21,-88.62C244.51,-75.6 268.66,-57.44 287.95,-42.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.88,-45.85 295.77,-37.05 285.67,-40.26 289.88,-45.85\"/>\n",
       "<text text-anchor=\"middle\" x=\"298.01\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">applies to</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x10ffd0520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kg = pydantic_output_parser.parse(output_graph_json_dict)\n",
    "\n",
    "visualize_knowledge_graph(kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaaay victory!!! Now, let's wrap this into a modified version of the original chain by using the RunnableLambda Object to do the \n",
    "intermediary step we were doing before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TokenError",
     "evalue": "('EOF in multi-line statement', (7, 0))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTokenError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Here instead of using the RunnableLambda we could have used the JsonOutputFunctionsParser, however langchain and pydantic had some compatibility issues\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# so we're extracting the json dict manually and then parsing it with the PydanticOutputParser \u001b[39;00m\n\u001b[1;32m     15\u001b[0m concept \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martificial neural network\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m---> 16\u001b[0m output_graph \u001b[38;5;241m=\u001b[39m \u001b[43mchain_diagram_viz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcept\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcept\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m visualize_knowledge_graph(output_graph)\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2043\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_with_context\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;66;03m# setup callbacks and context\u001b[39;00m\n\u001b[0;32m-> 2043\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_with_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2044\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m get_callback_manager_for_config(config)\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;66;03m# start the root run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/beta/runnables/context.py:157\u001b[0m, in \u001b[0;36mconfig_with_context\u001b[0;34m(config, steps)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfig_with_context\u001b[39m(\n\u001b[1;32m    145\u001b[0m     config: RunnableConfig,\n\u001b[1;32m    146\u001b[0m     steps: List[Runnable],\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunnableConfig:\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Patch a runnable config with context getters and setters.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m        The patched runnable config.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_config_with_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_setter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_getter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEvent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/beta/runnables/context.py:79\u001b[0m, in \u001b[0;36m_config_with_context\u001b[0;34m(config, steps, setter, getter, event_cls)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(k\u001b[38;5;241m.\u001b[39mstartswith(CONTEXT_CONFIG_PREFIX) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m---> 79\u001b[0m context_specs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     80\u001b[0m     (spec, i)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(steps)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m step\u001b[38;5;241m.\u001b[39mconfig_specs\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mstartswith(CONTEXT_CONFIG_PREFIX)\n\u001b[1;32m     84\u001b[0m ]\n\u001b[1;32m     85\u001b[0m grouped_by_key \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     86\u001b[0m     key: \u001b[38;5;28mlist\u001b[39m(group)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, group \u001b[38;5;129;01min\u001b[39;00m groupby(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m }\n\u001b[1;32m     92\u001b[0m deps_by_key \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     93\u001b[0m     key: \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m     94\u001b[0m         _key_from_id(dep) \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m group \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m (spec[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdependencies \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, group \u001b[38;5;129;01min\u001b[39;00m grouped_by_key\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     97\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/beta/runnables/context.py:82\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(k\u001b[38;5;241m.\u001b[39mstartswith(CONTEXT_CONFIG_PREFIX) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[1;32m     79\u001b[0m context_specs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     80\u001b[0m     (spec, i)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(steps)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_specs\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mstartswith(CONTEXT_CONFIG_PREFIX)\n\u001b[1;32m     84\u001b[0m ]\n\u001b[1;32m     85\u001b[0m grouped_by_key \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     86\u001b[0m     key: \u001b[38;5;28mlist\u001b[39m(group)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, group \u001b[38;5;129;01min\u001b[39;00m groupby(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m }\n\u001b[1;32m     92\u001b[0m deps_by_key \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     93\u001b[0m     key: \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m     94\u001b[0m         _key_from_id(dep) \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m group \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m (spec[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdependencies \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, group \u001b[38;5;129;01min\u001b[39;00m grouped_by_key\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     97\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:3308\u001b[0m, in \u001b[0;36mRunnableLambda.config_specs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3305\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfig_specs\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[ConfigurableFieldSpec]:\n\u001b[1;32m   3307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_unique_config_specs(\n\u001b[0;32m-> 3308\u001b[0m         spec \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeps\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mconfig_specs\n\u001b[1;32m   3309\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:3297\u001b[0m, in \u001b[0;36mRunnableLambda.deps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The dependencies of this runnable.\"\"\"\u001b[39;00m\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3297\u001b[0m     objects \u001b[38;5;241m=\u001b[39m \u001b[43mget_function_nonlocals\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   3299\u001b[0m     objects \u001b[38;5;241m=\u001b[39m get_function_nonlocals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc)\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/runnables/utils.py:247\u001b[0m, in \u001b[0;36mget_function_nonlocals\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the nonlocal variables accessed by a function.\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     tree \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mparse(textwrap\u001b[38;5;241m.\u001b[39mdedent(code))\n\u001b[1;32m    249\u001b[0m     visitor \u001b[38;5;241m=\u001b[39m FunctionNonLocals()\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/inspect.py:1139\u001b[0m, in \u001b[0;36mgetsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetsource\u001b[39m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the text of the source code for an object.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03m    The argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m    or code object.  The source code is returned as a single string.  An\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    OSError is raised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m     lines, lnum \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcelines\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lines)\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/inspect.py:1131\u001b[0m, in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lines, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlnum\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, lnum \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/inspect.py:1106\u001b[0m, in \u001b[0;36mgetblock\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokenize\u001b[38;5;241m.\u001b[39mgenerate_tokens(\u001b[38;5;28miter\u001b[39m(lines)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m)\n\u001b[0;32m-> 1106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m   1107\u001b[0m         blockfinder\u001b[38;5;241m.\u001b[39mtokeneater(\u001b[38;5;241m*\u001b[39m_token)\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (EndOfBlock, \u001b[38;5;167;01mIndentationError\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-langchain/lib/python3.10/tokenize.py:523\u001b[0m, in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:                                  \u001b[38;5;66;03m# continued statement\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m--> 523\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TokenError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOF in multi-line statement\u001b[39m\u001b[38;5;124m\"\u001b[39m, (lnum, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    524\u001b[0m     continued \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pos \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mmax\u001b[39m:\n",
      "\u001b[0;31mTokenError\u001b[0m: ('EOF in multi-line statement', (7, 0))"
     ]
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "\n",
    "def chain_diagram_viz():\n",
    "    \"\"\"Full chain to generate the formatted knowledge graph\"\"\"\n",
    "    openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n",
    "    llm_chat = ChatOpenAI(model=\"gpt-4-turbo\")    \n",
    "    llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "    pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "    return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "        what it is and what it relates to.\") | llm_with_tools | RunnableLambda(lambda x: x.additional_kwargs[\"function_call\"][\"arguments\"]) | pydantic_output_parser\n",
    "    # Here instead of using the RunnableLambda we could have used the JsonOutputFunctionsParser, however langchain and pydantic had some compatibility issues\n",
    "    # so we're extracting the json dict manually and then parsing it with the PydanticOutputParser \n",
    "concept = \"artificial neural network\" \n",
    "output_graph = chain_diagram_viz().invoke({\"concept\": concept})\n",
    "visualize_knowledge_graph(output_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! How about we put everything together under a class that represents this LangChain implementation of the ADEPT method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "@dataclass\n",
    "class ADEPT:\n",
    "    concept: str\n",
    "    llm_chat = ChatOpenAI()\n",
    "    \n",
    "    def chain_analogy(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "            what it is.\") | llm_chat\n",
    "\n",
    "    \n",
    "    def chain_diagram_viz(self):\n",
    "        \"\"\"Full chain to generate the formatted knowledge graph\"\"\"\n",
    "        openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph) \n",
    "        llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "        pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "        return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "            what it is and what it relates to.\") | llm_with_tools | RunnableLambda(lambda x: x.additional_kwargs[\"function_call\"][\"arguments\"]) | pydantic_output_parser\n",
    "        \n",
    "\n",
    "    def chain_example(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_plain_english(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_technical_definition(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm_chat\n",
    "    \n",
    "    def visualize_knowledge_graph(self, kg: KnowledgeGraph):\n",
    "        dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "        # Add nodes\n",
    "        for node in kg.nodes:\n",
    "            dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "        # Add edges\n",
    "        for edge in kg.edges:\n",
    "            dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "        # Render the graph\n",
    "        display(graphviz.Source(dot.source))\n",
    "        \n",
    "    # now let's write a __call__ method that runs all of the chains and generates a nice output just from the concept input.\n",
    "    def __call__(self):\n",
    "        analogy_chain = self.chain_analogy()\n",
    "        diagram_chain = self.chain_diagram_viz()\n",
    "        example_chain = self.chain_example()\n",
    "        plain_english_chain = self.chain_plain_english()\n",
    "        technical_definition_chain = self.chain_technical_definition()\n",
    "        map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "        output_explanation = map_chain.invoke({\"concept\": self.concept})\n",
    "        return output_explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADEPT(concept='langchain python library')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"langchain python library\"\n",
    "\n",
    "adept = ADEPT(concept)\n",
    "adept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_explanation = adept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"340pt\" height=\"133pt\"\n",
       " viewBox=\"0.00 0.00 339.95 132.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 128.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-128.5 335.95,-128.5 335.95,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" cx=\"124.02\" cy=\"-106.5\" rx=\"102.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.02\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">langchain python library</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"green\" cx=\"37.02\" cy=\"-18\" rx=\"37.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.02\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Python</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.83,-88.41C93.67,-75.32 75.36,-57.11 60.79,-42.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.34,-40.24 53.78,-35.67 58.41,-45.2 63.34,-40.24\"/>\n",
       "<text text-anchor=\"middle\" x=\"108.52\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">utilizes</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"green\" cx=\"212.02\" cy=\"-18\" rx=\"119.93\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.02\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Natural Language Processing</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.41,-88.41C154.3,-75.73 172.09,-58.25 186.58,-44.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"188.91,-46.62 193.59,-37.12 184.01,-41.63 188.91,-46.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.9\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">supports</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x1197bd6c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagram = output_explanation[\"diagram\"]\n",
    "\n",
    "adept.visualize_knowledge_graph(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The langchain python library is like a Swiss Army knife for language processing, providing all the tools you need in one convenient package.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"analogy\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Using langchain python library to tokenize and analyze text data for natural language processing tasks.\\n2. Implementing sentiment analysis with langchain python library to classify text as positive, negative, or neutral.\\n3. Creating a language model with langchain python library to generate realistic text based on input data.\\n4. Extracting key phrases and entities from text using langchain python library for information retrieval tasks.\\n5. Building a chatbot using langchain python library to interact with users in a conversational manner.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"example\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The langchain python library is a software tool that helps developers work with blockchain technology using the Python programming language.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"plain_english\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The langchain python library is a software tool that provides a set of functions and utilities for interacting with the Langchain protocol and conducting language-based blockchain operations in Python programming language.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"technical_def\"].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
